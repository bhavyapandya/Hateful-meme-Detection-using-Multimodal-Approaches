{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6913095,"sourceType":"datasetVersion","datasetId":3970193}],"dockerImageVersionId":30529,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade -q git+https://github.com/keras-team/keras-cv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T17:31:40.418911Z","iopub.execute_input":"2023-11-18T17:31:40.419689Z","iopub.status.idle":"2023-11-18T17:32:13.560373Z","shell.execute_reply.started":"2023-11-18T17:31:40.419655Z","shell.execute_reply":"2023-11-18T17:32:13.559060Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:32:13.562825Z","iopub.execute_input":"2023-11-18T17:32:13.563149Z","iopub.status.idle":"2023-11-18T17:32:24.972658Z","shell.execute_reply.started":"2023-11-18T17:32:13.563121Z","shell.execute_reply":"2023-11-18T17:32:24.971473Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:32:24.974463Z","iopub.execute_input":"2023-11-18T17:32:24.974876Z","iopub.status.idle":"2023-11-18T17:32:47.680568Z","shell.execute_reply.started":"2023-11-18T17:32:24.974839Z","shell.execute_reply":"2023-11-18T17:32:47.679651Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/dm-dataset/data mining project\"\ndata = pd.read_csv(DATA_PATH+\"/hatefulmemes.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:32:47.681819Z","iopub.execute_input":"2023-11-18T17:32:47.682093Z","iopub.status.idle":"2023-11-18T17:32:47.755375Z","shell.execute_reply.started":"2023-11-18T17:32:47.682068Z","shell.execute_reply":"2023-11-18T17:32:47.754457Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      id            img  label  \\\n0  42953  img/42953.png      0   \n1  23058  img/23058.png      0   \n2  13894  img/13894.png      0   \n3  37408  img/37408.png      0   \n4  82403  img/82403.png      0   \n\n                                                text  \n0   its their character not their color that matters  \n1  don't be afraid to love again everyone is not ...  \n2                           putting bows on your pet  \n3  i love everything and everybody! except for sq...  \n4  everybody loves chocolate chip cookies, even h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img</th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42953</td>\n      <td>img/42953.png</td>\n      <td>0</td>\n      <td>its their character not their color that matters</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23058</td>\n      <td>img/23058.png</td>\n      <td>0</td>\n      <td>don't be afraid to love again everyone is not ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13894</td>\n      <td>img/13894.png</td>\n      <td>0</td>\n      <td>putting bows on your pet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37408</td>\n      <td>img/37408.png</td>\n      <td>0</td>\n      <td>i love everything and everybody! except for sq...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82403</td>\n      <td>img/82403.png</td>\n      <td>0</td>\n      <td>everybody loves chocolate chip cookies, even h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:32:47.758730Z","iopub.execute_input":"2023-11-18T17:32:47.759189Z","iopub.status.idle":"2023-11-18T17:32:47.794951Z","shell.execute_reply.started":"2023-11-18T17:32:47.759163Z","shell.execute_reply":"2023-11-18T17:32:47.793980Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8500 entries, 0 to 8499\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   id      8500 non-null   int64 \n 1   img     8500 non-null   object\n 2   label   8500 non-null   int64 \n 3   text    8500 non-null   object\ndtypes: int64(2), object(2)\nmemory usage: 265.8+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:32:47.796001Z","iopub.execute_input":"2023-11-18T17:32:47.796269Z","iopub.status.idle":"2023-11-18T17:32:59.382900Z","shell.execute_reply.started":"2023-11-18T17:32:47.796245Z","shell.execute_reply":"2023-11-18T17:32:59.381741Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\n\n\nnltk.download('punkt')\nnltk.download('stopwords')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:32:59.384439Z","iopub.execute_input":"2023-11-18T17:32:59.384803Z","iopub.status.idle":"2023-11-18T17:33:00.545280Z","shell.execute_reply.started":"2023-11-18T17:32:59.384766Z","shell.execute_reply":"2023-11-18T17:33:00.544358Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport string\n\ndef clean_text_with_nltk(text):\n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Tokenize the text into words\n    words = word_tokenize(text)\n    \n    # Remove punctuation and numbers\n    words = [word for word in words if word.isalpha()]\n    \n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if word not in stop_words]\n    \n    # Join the cleaned words back into a string\n    cleaned_text = ' '.join(words)\n    \n    return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:33:00.546453Z","iopub.execute_input":"2023-11-18T17:33:00.546769Z","iopub.status.idle":"2023-11-18T17:33:00.554321Z","shell.execute_reply.started":"2023-11-18T17:33:00.546740Z","shell.execute_reply":"2023-11-18T17:33:00.553260Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data[\"clean_text\"] = data[\"text\"].apply(clean_text_with_nltk)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:33:00.555594Z","iopub.execute_input":"2023-11-18T17:33:00.555919Z","iopub.status.idle":"2023-11-18T17:33:03.754650Z","shell.execute_reply.started":"2023-11-18T17:33:00.555892Z","shell.execute_reply":"2023-11-18T17:33:03.753786Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras\nfrom tensorflow.keras import optimizers\nimport keras_cv\nimport numpy as np\nfrom keras_cv import bounding_box\nimport os\nimport resource\nfrom keras_cv import visualization\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:33:03.755827Z","iopub.execute_input":"2023-11-18T17:33:03.756139Z","iopub.status.idle":"2023-11-18T17:33:06.345566Z","shell.execute_reply.started":"2023-11-18T17:33:03.756111Z","shell.execute_reply":"2023-11-18T17:33:06.344763Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Using TensorFlow backend\n","output_type":"stream"}]},{"cell_type":"code","source":"# for object detection first lets try the yolov8 model backbone to extract image features with pretrained on coco dataset\nbackbone = keras_cv.models.YOLOV8Backbone.from_preset(\n        \"yolo_v8_xl_backbone_coco\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:33:06.346736Z","iopub.execute_input":"2023-11-18T17:33:06.347018Z","iopub.status.idle":"2023-11-18T17:33:20.603842Z","shell.execute_reply.started":"2023-11-18T17:33:06.346992Z","shell.execute_reply":"2023-11-18T17:33:20.602958Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-cv/models/yolov8/coco/yolov8_x_backbone.h5\n124353200/124353200 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\nmodel_name = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertModel.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:33:20.605070Z","iopub.execute_input":"2023-11-18T17:33:20.605342Z","iopub.status.idle":"2023-11-18T17:33:24.851386Z","shell.execute_reply.started":"2023-11-18T17:33:20.605318Z","shell.execute_reply":"2023-11-18T17:33:24.850305Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e45d56b115e943459934e32f27226af7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b29e5f6a431435cb7960d0fe0a1f588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a56feb6590a44cb5a63433fbe8b60344"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8118a856f4424dfb9ef8e6523e54bd96"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:33:24.852728Z","iopub.execute_input":"2023-11-18T17:33:24.853051Z","iopub.status.idle":"2023-11-18T17:33:24.862426Z","shell.execute_reply.started":"2023-11-18T17:33:24.853023Z","shell.execute_reply":"2023-11-18T17:33:24.861398Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm_notebook\ninference_resizing = keras_cv.layers.Resizing(\n  640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n)\n\nfeature_extractor_1 = tf.keras.models.Model(inputs=backbone.input, outputs=backbone.get_layer('stack4_spp_fast_output').output)\nflatten_layer = keras.layers.Flatten()(feature_extractor_1.output)\nfeature_extractor_2 = keras.models.Model(inputs=feature_extractor_1.input, outputs=flatten_layer)\nmax_length = 20\n\ndef text_feature_extraction(t):\n  \n  preprocessed_text = []\n  preprocessed_image = []\n  labels = []\n  for i in tqdm.notebook.tqdm(t.iterrows(), total=len(t)):\n    try:\n        image = keras.utils.load_img(\"/kaggle/input/dm-dataset/data mining project\"+f'''/{i[1][\"img\"]}''')\n        image = np.array(image)\n        image_batch = inference_resizing([image])\n        preprocessed_image.append(feature_extractor_2.predict(image_batch, verbose=0))\n        text_tokens = tokenizer(i[1][\"clean_text\"], padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length)\n        preprocessed_text.append(np.reshape(model(**text_tokens)['last_hidden_state'][:, 0, :].detach().numpy(), (768)))\n        labels.append(i[1][\"label\"])\n    except Exception as e:\n        pass\n  return preprocessed_text, preprocessed_image, labels\ntrain_text, train_image, train_label = text_feature_extraction(X_train)\ntest_text, test_image, test_label = text_feature_extraction(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:33:24.867975Z","iopub.execute_input":"2023-11-18T17:33:24.868462Z","iopub.status.idle":"2023-11-18T17:50:11.535226Z","shell.execute_reply.started":"2023-11-18T17:33:24.868426Z","shell.execute_reply":"2023-11-18T17:50:11.534231Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6800 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99b7537029a849f2a7e7f96316a29592"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"458bcf24fc0c4543a8e93d72e5029f67"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text = np.asarray(train_text)\ntrain_image = np.reshape(np.asarray(train_image), (len(train_text),256000))\ntrain_label = np.asarray(train_label)\ntest_text = np.asarray(test_text)\ntest_image = np.reshape(np.asarray(test_image), (len(test_text),256000))\ntest_label = np.asarray(test_label)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:50:11.536492Z","iopub.execute_input":"2023-11-18T17:50:11.536813Z","iopub.status.idle":"2023-11-18T17:50:12.865382Z","shell.execute_reply.started":"2023-11-18T17:50:11.536772Z","shell.execute_reply":"2023-11-18T17:50:12.864265Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(train_text.shape)\nprint(train_image.shape)\nprint(train_label.shape)\nprint(test_text.shape)\nprint(test_image.shape)\nprint(test_label.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:50:12.866907Z","iopub.execute_input":"2023-11-18T17:50:12.867277Z","iopub.status.idle":"2023-11-18T17:50:12.872810Z","shell.execute_reply.started":"2023-11-18T17:50:12.867248Z","shell.execute_reply":"2023-11-18T17:50:12.871885Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(3452, 768)\n(3452, 256000)\n(3452,)\n(826, 768)\n(826, 256000)\n(826,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.layers import Input, Concatenate, Dense\n\n# Define your text input layer with shape (768,)\ntext_input = Input(shape=(768,))\n\n# Define your image input layer with shape (256000,)\nimage_input = Input(shape=(256000,))\n\n# Define a neural network for processing the image input\nimage_network = keras.models.Sequential([\n    keras.layers.Dense(768, activation='relu', input_shape=(256000,)),\n   # Set the output dimension as needed\n])\n\n# Get the output from the image network\nimage_output = image_network(image_input)\n\n# Concatenate the text input and image output\nconcatenated_output = Concatenate()([text_input, image_output])\n\n# Create a new Sequential model for the final output\nfinal_model = keras.models.Sequential()\n # Assuming 512+512 dimensions\nfinal_model.add(Dense(1, activation='sigmoid', input_shape=(1536,)))  # Set the output dimension as needed\n\n# Create the complete model with two inputs and one output\ncomplete_model = keras.models.Model(inputs=[text_input, image_input], outputs=final_model(concatenated_output))\n\n# Compile the complete model with optimizer, loss function, and metrics\ncomplete_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:50:12.874087Z","iopub.execute_input":"2023-11-18T17:50:12.874385Z","iopub.status.idle":"2023-11-18T17:50:12.984313Z","shell.execute_reply.started":"2023-11-18T17:50:12.874361Z","shell.execute_reply":"2023-11-18T17:50:12.983157Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\ncomplete_model.fit([train_text, train_image], train_label ,\n                   validation_data=([test_text, test_image], test_label),\n                   epochs=10, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:50:12.985851Z","iopub.execute_input":"2023-11-18T17:50:12.986251Z","iopub.status.idle":"2023-11-18T17:51:17.945001Z","shell.execute_reply.started":"2023-11-18T17:50:12.986217Z","shell.execute_reply":"2023-11-18T17:51:17.943914Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/10\n108/108 [==============================] - 10s 67ms/step - loss: 3.7646 - accuracy: 0.5927 - val_loss: 0.6099 - val_accuracy: 0.7034\nEpoch 2/10\n108/108 [==============================] - 5s 50ms/step - loss: 0.5848 - accuracy: 0.7005 - val_loss: 0.5914 - val_accuracy: 0.7119\nEpoch 3/10\n108/108 [==============================] - 5s 50ms/step - loss: 0.5589 - accuracy: 0.7225 - val_loss: 0.6038 - val_accuracy: 0.6985\nEpoch 4/10\n108/108 [==============================] - 5s 50ms/step - loss: 0.5239 - accuracy: 0.7462 - val_loss: 0.6007 - val_accuracy: 0.7070\nEpoch 5/10\n108/108 [==============================] - 5s 50ms/step - loss: 0.4801 - accuracy: 0.7746 - val_loss: 0.5900 - val_accuracy: 0.7119\nEpoch 6/10\n108/108 [==============================] - 5s 50ms/step - loss: 0.4366 - accuracy: 0.8024 - val_loss: 0.6689 - val_accuracy: 0.6913\nEpoch 7/10\n108/108 [==============================] - 5s 49ms/step - loss: 0.3998 - accuracy: 0.8239 - val_loss: 0.6063 - val_accuracy: 0.6768\nEpoch 8/10\n108/108 [==============================] - 5s 50ms/step - loss: 0.3319 - accuracy: 0.8653 - val_loss: 0.6507 - val_accuracy: 0.6538\nEpoch 9/10\n108/108 [==============================] - 5s 49ms/step - loss: 0.3048 - accuracy: 0.8717 - val_loss: 0.6721 - val_accuracy: 0.6671\nEpoch 10/10\n108/108 [==============================] - 5s 50ms/step - loss: 0.2492 - accuracy: 0.9056 - val_loss: 0.7008 - val_accuracy: 0.6646\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f12904f0b50>"},"metadata":{}}]},{"cell_type":"code","source":"predictions = complete_model.predict([test_text, test_image])\npredictions_labels = []\nfor i in predictions:\n    if i >= 0.5:\n        predictions_labels.append(1)\n    else:\n        predictions_labels.append(0)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:54:50.610394Z","iopub.execute_input":"2023-11-18T17:54:50.611065Z","iopub.status.idle":"2023-11-18T17:54:52.711808Z","shell.execute_reply.started":"2023-11-18T17:54:50.611029Z","shell.execute_reply":"2023-11-18T17:54:52.710801Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"26/26 [==============================] - 0s 16ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\n\n# Compute the AUROC\nauroc = roc_auc_score(test_label, predictions_labels)\n\nprint(f'AUROC: {auroc}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:54:57.847810Z","iopub.execute_input":"2023-11-18T17:54:57.848222Z","iopub.status.idle":"2023-11-18T17:54:57.860512Z","shell.execute_reply.started":"2023-11-18T17:54:57.848189Z","shell.execute_reply":"2023-11-18T17:54:57.859490Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"AUROC: 0.6509426847662142\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Compute confusion matrix\ncm = confusion_matrix(test_label, predictions_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_label, predictions_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:57:16.756664Z","iopub.execute_input":"2023-11-18T17:57:16.757033Z","iopub.status.idle":"2023-11-18T17:57:17.275248Z","shell.execute_reply.started":"2023-11-18T17:57:16.757004Z","shell.execute_reply":"2023-11-18T17:57:17.274065Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.75      0.70      0.73       520\n           1       0.54      0.60      0.57       306\n\n    accuracy                           0.66       826\n   macro avg       0.65      0.65      0.65       826\nweighted avg       0.67      0.66      0.67       826\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Second Approach","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:51:17.954182Z","iopub.execute_input":"2023-11-18T17:51:17.954514Z","iopub.status.idle":"2023-11-18T17:51:17.973886Z","shell.execute_reply.started":"2023-11-18T17:51:17.954484Z","shell.execute_reply":"2023-11-18T17:51:17.970651Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"      id            img  label  \\\n0  42953  img/42953.png      0   \n1  23058  img/23058.png      0   \n2  13894  img/13894.png      0   \n3  37408  img/37408.png      0   \n4  82403  img/82403.png      0   \n\n                                                text  \\\n0   its their character not their color that matters   \n1  don't be afraid to love again everyone is not ...   \n2                           putting bows on your pet   \n3  i love everything and everybody! except for sq...   \n4  everybody loves chocolate chip cookies, even h...   \n\n                                          clean_text  \n0                            character color matters  \n1                       afraid love everyone like ex  \n2                                   putting bows pet  \n3  love everything everybody except squirrels hat...  \n4  everybody loves chocolate chip cookies even hi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img</th>\n      <th>label</th>\n      <th>text</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42953</td>\n      <td>img/42953.png</td>\n      <td>0</td>\n      <td>its their character not their color that matters</td>\n      <td>character color matters</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23058</td>\n      <td>img/23058.png</td>\n      <td>0</td>\n      <td>don't be afraid to love again everyone is not ...</td>\n      <td>afraid love everyone like ex</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13894</td>\n      <td>img/13894.png</td>\n      <td>0</td>\n      <td>putting bows on your pet</td>\n      <td>putting bows pet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37408</td>\n      <td>img/37408.png</td>\n      <td>0</td>\n      <td>i love everything and everybody! except for sq...</td>\n      <td>love everything everybody except squirrels hat...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82403</td>\n      <td>img/82403.png</td>\n      <td>0</td>\n      <td>everybody loves chocolate chip cookies, even h...</td>\n      <td>everybody loves chocolate chip cookies even hi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import json\nimport re\nimport string\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom PIL import Image\nimport tensorflow_hub as hub\nfrom tqdm import tqdm\nimport os\n\n# Define parameters\nmax_sequence_length = 100  # Adjust as needed\nimage_size = (224, 224)\n\ntrain_text_data = []\ntrain_image_data_paths = []\ntrain_labels = []\n\ntest_text_data = []\ntest_image_data_paths = []\ntest_labels = []\nfor img, text, label in zip(X_train[\"img\"].values, X_train['clean_text'].values, X_train['label'].values):\n    if os.path.exists(DATA_PATH+f'''/{img}'''):\n        train_text_data.append(text)\n        train_image_data_paths.append(img)\n        train_labels.append(label)\n\nfor img, text, label in zip(X_test[\"img\"].values, X_test['clean_text'].values, X_test['label'].values):\n    if os.path.exists(DATA_PATH+f'''/{img}'''):\n        test_text_data.append(text)\n        test_image_data_paths.append(img)\n        test_labels.append(label)\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_text_data)\n\n    \ntrain_sequences = tokenizer.texts_to_sequences(train_text_data)\ntrain_padded_sequences = pad_sequences(train_sequences, maxlen=max_sequence_length)\n\ntest_sequences = tokenizer.texts_to_sequences(test_text_data)\ntest_padded_sequences = pad_sequences(test_sequences, maxlen=max_sequence_length)\n  \n# Function to preprocess image data\ndef preprocess_image(image_path, image_size):\n\n    image = Image.open(DATA_PATH+f'''/{image_path}''')\n    image = image.resize(image_size)  # Adjust the size as needed\n        # Convert the image to RGB\n    image = image.convert('RGB')\n    image = np.array(image)  # Normalize image data\n    return image\n\n\n\n\n# Preprocess image data\ntrain_image_data = [preprocess_image(path, image_size) for path in tqdm(train_image_data_paths)]\ntest_image_data = [preprocess_image(path, image_size) for path in tqdm(test_image_data_paths)]\nword_index = tokenizer.word_index\n# Convert text and image data to TensorFlow tensors\ntrain_text_data = tf.constant(train_padded_sequences)\ntest_text_data = tf.constant(test_padded_sequences)\ntrain_image_data = tf.constant(train_image_data)\ntest_image_data = tf.constant(test_image_data)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-18T18:10:45.383456Z","iopub.execute_input":"2023-11-18T18:10:45.384402Z","iopub.status.idle":"2023-11-18T18:19:39.566174Z","shell.execute_reply.started":"2023-11-18T18:10:45.384364Z","shell.execute_reply":"2023-11-18T18:19:39.565032Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"\n\n  0%|          | 0/3452 [00:00<?, ?it/s]\u001b[A\u001b[A\n\n  0%|          | 6/3452 [00:00<01:01, 55.74it/s]\u001b[A\u001b[A\n\n  0%|          | 13/3452 [00:00<00:57, 59.54it/s]\u001b[A\u001b[A\n\n  1%|          | 20/3452 [00:00<00:55, 62.19it/s]\u001b[A\u001b[A\n\n  1%|          | 27/3452 [00:00<00:55, 61.43it/s]\u001b[A\u001b[A\n\n  1%|          | 34/3452 [00:00<00:57, 59.28it/s]\u001b[A\u001b[A\n\n  1%|          | 41/3452 [00:00<00:56, 60.71it/s]\u001b[A\u001b[A\n\n  1%|▏         | 48/3452 [00:00<00:56, 60.44it/s]\u001b[A\u001b[A\n\n  2%|▏         | 55/3452 [00:00<00:55, 61.52it/s]\u001b[A\u001b[A\n\n  2%|▏         | 62/3452 [00:01<00:56, 59.88it/s]\u001b[A\u001b[A\n\n  2%|▏         | 69/3452 [00:01<00:59, 56.47it/s]\u001b[A\u001b[A\n\n  2%|▏         | 75/3452 [00:01<01:00, 55.40it/s]\u001b[A\u001b[A\n\n  2%|▏         | 82/3452 [00:01<00:58, 57.94it/s]\u001b[A\u001b[A\n\n  3%|▎         | 90/3452 [00:01<00:54, 61.34it/s]\u001b[A\u001b[A\n\n  3%|▎         | 97/3452 [00:01<00:58, 57.76it/s]\u001b[A\u001b[A\n\n  3%|▎         | 104/3452 [00:01<00:56, 59.53it/s]\u001b[A\u001b[A\n\n  3%|▎         | 111/3452 [00:01<00:56, 58.67it/s]\u001b[A\u001b[A\n\n  3%|▎         | 118/3452 [00:01<00:54, 60.78it/s]\u001b[A\u001b[A\n\n  4%|▎         | 125/3452 [00:02<00:54, 61.20it/s]\u001b[A\u001b[A\n\n  4%|▍         | 132/3452 [00:02<00:55, 60.28it/s]\u001b[A\u001b[A\n\n  4%|▍         | 139/3452 [00:02<00:55, 60.22it/s]\u001b[A\u001b[A\n\n  4%|▍         | 146/3452 [00:02<00:54, 60.19it/s]\u001b[A\u001b[A\n\n  4%|▍         | 153/3452 [00:02<00:53, 62.23it/s]\u001b[A\u001b[A\n\n  5%|▍         | 160/3452 [00:02<00:54, 60.18it/s]\u001b[A\u001b[A\n\n  5%|▍         | 167/3452 [00:02<00:57, 57.39it/s]\u001b[A\u001b[A\n\n  5%|▌         | 173/3452 [00:02<00:59, 55.25it/s]\u001b[A\u001b[A\n\n  5%|▌         | 179/3452 [00:03<01:01, 53.16it/s]\u001b[A\u001b[A\n\n  5%|▌         | 185/3452 [00:03<01:05, 50.12it/s]\u001b[A\u001b[A\n\n  6%|▌         | 191/3452 [00:03<01:02, 52.11it/s]\u001b[A\u001b[A\n\n  6%|▌         | 197/3452 [00:03<01:02, 51.69it/s]\u001b[A\u001b[A\n\n  6%|▌         | 204/3452 [00:03<00:58, 55.38it/s]\u001b[A\u001b[A\n\n  6%|▌         | 211/3452 [00:03<00:55, 58.62it/s]\u001b[A\u001b[A\n\n  6%|▋         | 217/3452 [00:03<00:55, 57.78it/s]\u001b[A\u001b[A\n\n  6%|▋         | 224/3452 [00:03<00:55, 57.73it/s]\u001b[A\u001b[A\n\n  7%|▋         | 230/3452 [00:03<00:56, 57.40it/s]\u001b[A\u001b[A\n\n  7%|▋         | 236/3452 [00:04<00:55, 58.04it/s]\u001b[A\u001b[A\n\n  7%|▋         | 242/3452 [00:04<00:56, 56.88it/s]\u001b[A\u001b[A\n\n  7%|▋         | 250/3452 [00:04<00:54, 59.02it/s]\u001b[A\u001b[A\n\n  7%|▋         | 256/3452 [00:04<00:58, 55.06it/s]\u001b[A\u001b[A\n\n  8%|▊         | 262/3452 [00:04<00:58, 54.98it/s]\u001b[A\u001b[A\n\n  8%|▊         | 268/3452 [00:04<00:57, 54.94it/s]\u001b[A\u001b[A\n\n  8%|▊         | 274/3452 [00:04<01:01, 51.93it/s]\u001b[A\u001b[A\n\n  8%|▊         | 280/3452 [00:04<00:59, 53.50it/s]\u001b[A\u001b[A\n\n  8%|▊         | 286/3452 [00:04<00:59, 53.13it/s]\u001b[A\u001b[A\n\n  8%|▊         | 293/3452 [00:05<00:55, 57.39it/s]\u001b[A\u001b[A\n\n  9%|▊         | 301/3452 [00:05<00:50, 62.34it/s]\u001b[A\u001b[A\n\n  9%|▉         | 308/3452 [00:05<00:51, 60.95it/s]\u001b[A\u001b[A\n\n  9%|▉         | 316/3452 [00:05<00:48, 64.42it/s]\u001b[A\u001b[A\n\n  9%|▉         | 324/3452 [00:05<00:48, 64.08it/s]\u001b[A\u001b[A\n\n 10%|▉         | 331/3452 [00:05<00:49, 62.53it/s]\u001b[A\u001b[A\n\n 10%|▉         | 338/3452 [00:05<00:49, 62.57it/s]\u001b[A\u001b[A\n\n 10%|█         | 346/3452 [00:05<00:46, 66.78it/s]\u001b[A\u001b[A\n\n 10%|█         | 353/3452 [00:06<00:47, 64.59it/s]\u001b[A\u001b[A\n\n 10%|█         | 360/3452 [00:06<00:48, 63.61it/s]\u001b[A\u001b[A\n\n 11%|█         | 367/3452 [00:06<00:50, 61.69it/s]\u001b[A\u001b[A\n\n 11%|█         | 374/3452 [00:06<00:53, 57.97it/s]\u001b[A\u001b[A\n\n 11%|█         | 380/3452 [00:06<00:56, 53.98it/s]\u001b[A\u001b[A\n\n 11%|█         | 386/3452 [00:06<00:55, 54.77it/s]\u001b[A\u001b[A\n\n 11%|█▏        | 392/3452 [00:06<00:55, 55.07it/s]\u001b[A\u001b[A\n\n 12%|█▏        | 399/3452 [00:06<00:52, 57.81it/s]\u001b[A\u001b[A\n\n 12%|█▏        | 407/3452 [00:06<00:50, 60.78it/s]\u001b[A\u001b[A\n\n 12%|█▏        | 414/3452 [00:07<00:51, 58.92it/s]\u001b[A\u001b[A\n\n 12%|█▏        | 420/3452 [00:07<00:54, 56.14it/s]\u001b[A\u001b[A\n\n 12%|█▏        | 426/3452 [00:07<00:55, 54.95it/s]\u001b[A\u001b[A\n\n 13%|█▎        | 432/3452 [00:07<00:57, 52.60it/s]\u001b[A\u001b[A\n\n 13%|█▎        | 438/3452 [00:07<00:59, 50.40it/s]\u001b[A\u001b[A\n\n 13%|█▎        | 446/3452 [00:07<00:54, 55.53it/s]\u001b[A\u001b[A\n\n 13%|█▎        | 452/3452 [00:07<00:55, 54.15it/s]\u001b[A\u001b[A\n\n 13%|█▎        | 460/3452 [00:07<00:50, 59.51it/s]\u001b[A\u001b[A\n\n 14%|█▎        | 467/3452 [00:08<00:49, 60.73it/s]\u001b[A\u001b[A\n\n 14%|█▎        | 474/3452 [00:08<00:49, 60.58it/s]\u001b[A\u001b[A\n\n 14%|█▍        | 482/3452 [00:08<00:47, 62.49it/s]\u001b[A\u001b[A\n\n 14%|█▍        | 489/3452 [00:08<00:48, 60.55it/s]\u001b[A\u001b[A\n\n 14%|█▍        | 497/3452 [00:08<00:45, 65.47it/s]\u001b[A\u001b[A\n\n 15%|█▍        | 504/3452 [00:08<00:45, 64.18it/s]\u001b[A\u001b[A\n\n 15%|█▍        | 511/3452 [00:08<00:48, 60.26it/s]\u001b[A\u001b[A\n\n 15%|█▌        | 518/3452 [00:08<00:48, 60.63it/s]\u001b[A\u001b[A\n\n 15%|█▌        | 525/3452 [00:08<00:48, 59.81it/s]\u001b[A\u001b[A\n\n 15%|█▌        | 532/3452 [00:09<00:48, 60.04it/s]\u001b[A\u001b[A\n\n 16%|█▌        | 539/3452 [00:09<00:51, 56.23it/s]\u001b[A\u001b[A\n\n 16%|█▌        | 545/3452 [00:09<00:54, 53.30it/s]\u001b[A\u001b[A\n\n 16%|█▌        | 551/3452 [00:09<00:57, 50.70it/s]\u001b[A\u001b[A\n\n 16%|█▌        | 557/3452 [00:09<00:56, 50.95it/s]\u001b[A\u001b[A\n\n 16%|█▋        | 563/3452 [00:09<00:56, 51.15it/s]\u001b[A\u001b[A\n\n 16%|█▋        | 569/3452 [00:09<00:55, 52.26it/s]\u001b[A\u001b[A\n\n 17%|█▋        | 575/3452 [00:09<00:56, 50.85it/s]\u001b[A\u001b[A\n\n 17%|█▋        | 581/3452 [00:10<00:55, 51.97it/s]\u001b[A\u001b[A\n\n 17%|█▋        | 588/3452 [00:10<00:51, 55.83it/s]\u001b[A\u001b[A\n\n 17%|█▋        | 596/3452 [00:10<00:46, 61.19it/s]\u001b[A\u001b[A\n\n 17%|█▋        | 603/3452 [00:10<00:52, 54.51it/s]\u001b[A\u001b[A\n\n 18%|█▊        | 609/3452 [00:10<00:51, 55.71it/s]\u001b[A\u001b[A\n\n 18%|█▊        | 615/3452 [00:10<00:49, 56.76it/s]\u001b[A\u001b[A\n\n 18%|█▊        | 623/3452 [00:10<00:45, 62.05it/s]\u001b[A\u001b[A\n\n 18%|█▊        | 630/3452 [00:10<00:46, 60.91it/s]\u001b[A\u001b[A\n\n 18%|█▊        | 637/3452 [00:11<00:48, 58.55it/s]\u001b[A\u001b[A\n\n 19%|█▊        | 645/3452 [00:11<00:44, 63.31it/s]\u001b[A\u001b[A\n\n 19%|█▉        | 652/3452 [00:11<00:46, 60.05it/s]\u001b[A\u001b[A\n\n 19%|█▉        | 659/3452 [00:11<00:47, 59.29it/s]\u001b[A\u001b[A\n\n 19%|█▉        | 665/3452 [00:11<00:47, 58.17it/s]\u001b[A\u001b[A\n\n 19%|█▉        | 671/3452 [00:11<00:50, 54.75it/s]\u001b[A\u001b[A\n\n 20%|█▉        | 679/3452 [00:11<00:45, 60.28it/s]\u001b[A\u001b[A\n\n 20%|█▉        | 687/3452 [00:11<00:44, 62.67it/s]\u001b[A\u001b[A\n\n 20%|██        | 694/3452 [00:11<00:43, 62.82it/s]\u001b[A\u001b[A\n\n 20%|██        | 701/3452 [00:12<00:44, 61.77it/s]\u001b[A\u001b[A\n\n 21%|██        | 708/3452 [00:12<00:46, 59.11it/s]\u001b[A\u001b[A\n\n 21%|██        | 715/3452 [00:12<00:44, 60.85it/s]\u001b[A\u001b[A\n\n 21%|██        | 722/3452 [00:12<00:47, 58.03it/s]\u001b[A\u001b[A\n\n 21%|██        | 729/3452 [00:12<00:44, 61.05it/s]\u001b[A\u001b[A\n\n 21%|██▏       | 736/3452 [00:12<00:45, 59.92it/s]\u001b[A\u001b[A\n\n 22%|██▏       | 743/3452 [00:12<00:43, 62.48it/s]\u001b[A\u001b[A\n\n 22%|██▏       | 750/3452 [00:12<00:47, 57.04it/s]\u001b[A\u001b[A\n\n 22%|██▏       | 757/3452 [00:13<00:46, 57.95it/s]\u001b[A\u001b[A\n\n 22%|██▏       | 763/3452 [00:13<00:49, 54.25it/s]\u001b[A\u001b[A\n\n 22%|██▏       | 769/3452 [00:13<00:50, 53.17it/s]\u001b[A\u001b[A\n\n 22%|██▏       | 776/3452 [00:13<00:47, 56.57it/s]\u001b[A\u001b[A\n\n 23%|██▎       | 784/3452 [00:13<00:44, 60.07it/s]\u001b[A\u001b[A\n\n 23%|██▎       | 791/3452 [00:13<00:42, 61.94it/s]\u001b[A\u001b[A\n\n 23%|██▎       | 798/3452 [00:13<00:44, 60.01it/s]\u001b[A\u001b[A\n\n 23%|██▎       | 806/3452 [00:13<00:41, 64.11it/s]\u001b[A\u001b[A\n\n 24%|██▎       | 813/3452 [00:13<00:41, 62.91it/s]\u001b[A\u001b[A\n\n 24%|██▍       | 820/3452 [00:14<00:44, 59.58it/s]\u001b[A\u001b[A\n\n 24%|██▍       | 829/3452 [00:14<00:39, 67.01it/s]\u001b[A\u001b[A\n\n 24%|██▍       | 836/3452 [00:14<00:42, 62.22it/s]\u001b[A\u001b[A\n\n 24%|██▍       | 843/3452 [00:14<00:42, 61.85it/s]\u001b[A\u001b[A\n\n 25%|██▍       | 851/3452 [00:14<00:40, 64.11it/s]\u001b[A\u001b[A\n\n 25%|██▍       | 859/3452 [00:14<00:39, 64.87it/s]\u001b[A\u001b[A\n\n 25%|██▌       | 866/3452 [00:14<00:40, 63.09it/s]\u001b[A\u001b[A\n\n 25%|██▌       | 873/3452 [00:14<00:43, 59.38it/s]\u001b[A\u001b[A\n\n 26%|██▌       | 881/3452 [00:15<00:42, 60.27it/s]\u001b[A\u001b[A\n\n 26%|██▌       | 888/3452 [00:15<00:42, 59.78it/s]\u001b[A\u001b[A\n\n 26%|██▌       | 895/3452 [00:15<00:42, 60.65it/s]\u001b[A\u001b[A\n\n 26%|██▌       | 902/3452 [00:15<00:43, 58.85it/s]\u001b[A\u001b[A\n\n 26%|██▋       | 910/3452 [00:15<00:40, 63.21it/s]\u001b[A\u001b[A\n\n 27%|██▋       | 917/3452 [00:15<00:42, 59.50it/s]\u001b[A\u001b[A\n\n 27%|██▋       | 924/3452 [00:15<00:41, 61.45it/s]\u001b[A\u001b[A\n\n 27%|██▋       | 931/3452 [00:15<00:41, 61.12it/s]\u001b[A\u001b[A\n\n 27%|██▋       | 938/3452 [00:15<00:41, 60.60it/s]\u001b[A\u001b[A\n\n 27%|██▋       | 945/3452 [00:16<00:46, 54.47it/s]\u001b[A\u001b[A\n\n 28%|██▊       | 951/3452 [00:16<00:44, 55.83it/s]\u001b[A\u001b[A\n\n 28%|██▊       | 958/3452 [00:16<00:43, 56.94it/s]\u001b[A\u001b[A\n\n 28%|██▊       | 965/3452 [00:16<00:42, 58.88it/s]\u001b[A\u001b[A\n\n 28%|██▊       | 972/3452 [00:16<00:41, 60.39it/s]\u001b[A\u001b[A\n\n 28%|██▊       | 979/3452 [00:16<00:42, 57.79it/s]\u001b[A\u001b[A\n\n 29%|██▊       | 987/3452 [00:16<00:41, 60.07it/s]\u001b[A\u001b[A\n\n 29%|██▉       | 995/3452 [00:16<00:38, 64.29it/s]\u001b[A\u001b[A\n\n 29%|██▉       | 1002/3452 [00:17<00:39, 62.61it/s]\u001b[A\u001b[A\n\n 29%|██▉       | 1009/3452 [00:17<00:43, 56.70it/s]\u001b[A\u001b[A\n\n 29%|██▉       | 1016/3452 [00:17<00:40, 59.44it/s]\u001b[A\u001b[A\n\n 30%|██▉       | 1023/3452 [00:17<00:44, 54.95it/s]\u001b[A\u001b[A\n\n 30%|██▉       | 1029/3452 [00:17<00:46, 52.51it/s]\u001b[A\u001b[A\n\n 30%|██▉       | 1035/3452 [00:17<00:46, 52.04it/s]\u001b[A\u001b[A\n\n 30%|███       | 1041/3452 [00:17<00:45, 53.21it/s]\u001b[A\u001b[A\n\n 30%|███       | 1048/3452 [00:17<00:42, 56.30it/s]\u001b[A\u001b[A\n\n 31%|███       | 1054/3452 [00:18<00:45, 52.13it/s]\u001b[A\u001b[A\n\n 31%|███       | 1062/3452 [00:18<00:40, 59.11it/s]\u001b[A\u001b[A\n\n 31%|███       | 1069/3452 [00:18<00:38, 61.91it/s]\u001b[A\u001b[A\n\n 31%|███       | 1077/3452 [00:18<00:36, 65.10it/s]\u001b[A\u001b[A\n\n 31%|███▏      | 1084/3452 [00:18<00:37, 63.63it/s]\u001b[A\u001b[A\n\n 32%|███▏      | 1091/3452 [00:18<00:40, 57.80it/s]\u001b[A\u001b[A\n\n 32%|███▏      | 1098/3452 [00:18<00:38, 60.83it/s]\u001b[A\u001b[A\n\n 32%|███▏      | 1105/3452 [00:18<00:39, 60.06it/s]\u001b[A\u001b[A\n\n 32%|███▏      | 1112/3452 [00:19<00:42, 55.04it/s]\u001b[A\u001b[A\n\n 32%|███▏      | 1120/3452 [00:19<00:40, 57.86it/s]\u001b[A\u001b[A\n\n 33%|███▎      | 1126/3452 [00:19<00:40, 57.05it/s]\u001b[A\u001b[A\n\n 33%|███▎      | 1133/3452 [00:19<00:39, 58.57it/s]\u001b[A\u001b[A\n\n 33%|███▎      | 1139/3452 [00:19<00:42, 54.60it/s]\u001b[A\u001b[A\n\n 33%|███▎      | 1145/3452 [00:19<00:43, 53.61it/s]\u001b[A\u001b[A\n\n 33%|███▎      | 1151/3452 [00:19<00:42, 54.32it/s]\u001b[A\u001b[A\n\n 34%|███▎      | 1159/3452 [00:19<00:38, 59.29it/s]\u001b[A\u001b[A\n\n 34%|███▍      | 1166/3452 [00:19<00:37, 61.23it/s]\u001b[A\u001b[A\n\n 34%|███▍      | 1175/3452 [00:20<00:33, 68.00it/s]\u001b[A\u001b[A\n\n 34%|███▍      | 1182/3452 [00:20<00:35, 63.80it/s]\u001b[A\u001b[A\n\n 34%|███▍      | 1190/3452 [00:20<00:33, 67.73it/s]\u001b[A\u001b[A\n\n 35%|███▍      | 1197/3452 [00:20<00:34, 65.69it/s]\u001b[A\u001b[A\n\n 35%|███▍      | 1204/3452 [00:20<00:38, 59.09it/s]\u001b[A\u001b[A\n\n 35%|███▌      | 1211/3452 [00:20<00:39, 56.81it/s]\u001b[A\u001b[A\n\n 35%|███▌      | 1219/3452 [00:20<00:36, 60.38it/s]\u001b[A\u001b[A\n\n 36%|███▌      | 1226/3452 [00:20<00:37, 58.89it/s]\u001b[A\u001b[A\n\n 36%|███▌      | 1234/3452 [00:21<00:36, 61.21it/s]\u001b[A\u001b[A\n\n 36%|███▌      | 1241/3452 [00:21<00:36, 60.28it/s]\u001b[A\u001b[A\n\n 36%|███▌      | 1248/3452 [00:21<00:35, 62.22it/s]\u001b[A\u001b[A\n\n 36%|███▋      | 1255/3452 [00:21<00:39, 55.53it/s]\u001b[A\u001b[A\n\n 37%|███▋      | 1262/3452 [00:21<00:37, 57.85it/s]\u001b[A\u001b[A\n\n 37%|███▋      | 1268/3452 [00:21<00:38, 56.09it/s]\u001b[A\u001b[A\n\n 37%|███▋      | 1274/3452 [00:21<00:38, 57.04it/s]\u001b[A\u001b[A\n\n 37%|███▋      | 1280/3452 [00:21<00:41, 52.25it/s]\u001b[A\u001b[A\n\n 37%|███▋      | 1287/3452 [00:21<00:38, 56.04it/s]\u001b[A\u001b[A\n\n 37%|███▋      | 1294/3452 [00:22<00:37, 57.25it/s]\u001b[A\u001b[A\n\n 38%|███▊      | 1301/3452 [00:22<00:37, 58.13it/s]\u001b[A\u001b[A\n\n 38%|███▊      | 1308/3452 [00:22<00:35, 59.59it/s]\u001b[A\u001b[A\n\n 38%|███▊      | 1316/3452 [00:22<00:33, 63.11it/s]\u001b[A\u001b[A\n\n 38%|███▊      | 1323/3452 [00:22<00:37, 56.10it/s]\u001b[A\u001b[A\n\n 38%|███▊      | 1329/3452 [00:22<00:38, 55.40it/s]\u001b[A\u001b[A\n\n 39%|███▊      | 1336/3452 [00:22<00:36, 57.97it/s]\u001b[A\u001b[A\n\n 39%|███▉      | 1342/3452 [00:22<00:37, 56.97it/s]\u001b[A\u001b[A\n\n 39%|███▉      | 1350/3452 [00:23<00:34, 61.36it/s]\u001b[A\u001b[A\n\n 39%|███▉      | 1357/3452 [00:23<00:36, 58.11it/s]\u001b[A\u001b[A\n\n 39%|███▉      | 1363/3452 [00:23<00:36, 57.70it/s]\u001b[A\u001b[A\n\n 40%|███▉      | 1369/3452 [00:23<00:37, 54.86it/s]\u001b[A\u001b[A\n\n 40%|███▉      | 1378/3452 [00:23<00:34, 60.91it/s]\u001b[A\u001b[A\n\n 40%|████      | 1385/3452 [00:23<00:34, 59.68it/s]\u001b[A\u001b[A\n\n 40%|████      | 1392/3452 [00:23<00:33, 62.29it/s]\u001b[A\u001b[A\n\n 41%|████      | 1399/3452 [00:23<00:34, 59.56it/s]\u001b[A\u001b[A\n\n 41%|████      | 1406/3452 [00:24<00:35, 56.83it/s]\u001b[A\u001b[A\n\n 41%|████      | 1413/3452 [00:24<00:34, 58.63it/s]\u001b[A\u001b[A\n\n 41%|████      | 1419/3452 [00:24<00:34, 58.21it/s]\u001b[A\u001b[A\n\n 41%|████▏     | 1425/3452 [00:24<00:36, 55.42it/s]\u001b[A\u001b[A\n\n 41%|████▏     | 1431/3452 [00:24<00:37, 54.50it/s]\u001b[A\u001b[A\n\n 42%|████▏     | 1438/3452 [00:24<00:34, 57.58it/s]\u001b[A\u001b[A\n\n 42%|████▏     | 1445/3452 [00:24<00:34, 58.35it/s]\u001b[A\u001b[A\n\n 42%|████▏     | 1451/3452 [00:24<00:36, 55.38it/s]\u001b[A\u001b[A\n\n 42%|████▏     | 1460/3452 [00:24<00:31, 63.88it/s]\u001b[A\u001b[A\n\n 42%|████▏     | 1467/3452 [00:25<00:31, 63.36it/s]\u001b[A\u001b[A\n\n 43%|████▎     | 1474/3452 [00:25<00:32, 60.19it/s]\u001b[A\u001b[A\n\n 43%|████▎     | 1482/3452 [00:25<00:31, 62.60it/s]\u001b[A\u001b[A\n\n 43%|████▎     | 1489/3452 [00:25<00:33, 58.88it/s]\u001b[A\u001b[A\n\n 43%|████▎     | 1495/3452 [00:25<00:34, 57.47it/s]\u001b[A\u001b[A\n\n 43%|████▎     | 1501/3452 [00:25<00:33, 57.45it/s]\u001b[A\u001b[A\n\n 44%|████▎     | 1507/3452 [00:25<00:34, 55.93it/s]\u001b[A\u001b[A\n\n 44%|████▍     | 1514/3452 [00:25<00:34, 56.51it/s]\u001b[A\u001b[A\n\n 44%|████▍     | 1521/3452 [00:25<00:32, 58.65it/s]\u001b[A\u001b[A\n\n 44%|████▍     | 1528/3452 [00:26<00:32, 58.67it/s]\u001b[A\u001b[A\n\n 44%|████▍     | 1535/3452 [00:26<00:31, 61.13it/s]\u001b[A\u001b[A\n\n 45%|████▍     | 1542/3452 [00:26<00:32, 58.61it/s]\u001b[A\u001b[A\n\n 45%|████▍     | 1548/3452 [00:26<00:33, 56.20it/s]\u001b[A\u001b[A\n\n 45%|████▌     | 1554/3452 [00:26<00:34, 55.08it/s]\u001b[A\u001b[A\n\n 45%|████▌     | 1560/3452 [00:26<00:34, 55.61it/s]\u001b[A\u001b[A\n\n 45%|████▌     | 1566/3452 [00:26<00:33, 56.09it/s]\u001b[A\u001b[A\n\n 46%|████▌     | 1573/3452 [00:26<00:33, 56.44it/s]\u001b[A\u001b[A\n\n 46%|████▌     | 1579/3452 [00:27<00:36, 52.00it/s]\u001b[A\u001b[A\n\n 46%|████▌     | 1585/3452 [00:27<00:35, 52.38it/s]\u001b[A\u001b[A\n\n 46%|████▌     | 1591/3452 [00:27<00:37, 50.30it/s]\u001b[A\u001b[A\n\n 46%|████▋     | 1597/3452 [00:27<00:36, 50.28it/s]\u001b[A\u001b[A\n\n 46%|████▋     | 1605/3452 [00:27<00:32, 56.91it/s]\u001b[A\u001b[A\n\n 47%|████▋     | 1611/3452 [00:27<00:32, 56.71it/s]\u001b[A\u001b[A\n\n 47%|████▋     | 1617/3452 [00:27<00:32, 57.26it/s]\u001b[A\u001b[A\n\n 47%|████▋     | 1624/3452 [00:27<00:30, 60.73it/s]\u001b[A\u001b[A\n\n 47%|████▋     | 1631/3452 [00:27<00:31, 56.93it/s]\u001b[A\u001b[A\n\n 47%|████▋     | 1637/3452 [00:28<00:31, 57.18it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 1643/3452 [00:28<00:32, 55.18it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 1649/3452 [00:28<00:32, 55.05it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 1656/3452 [00:28<00:32, 55.53it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 1662/3452 [00:28<00:31, 56.09it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 1668/3452 [00:28<00:31, 56.62it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 1674/3452 [00:28<00:32, 54.49it/s]\u001b[A\u001b[A\n\n 49%|████▊     | 1680/3452 [00:28<00:32, 55.12it/s]\u001b[A\u001b[A\n\n 49%|████▉     | 1687/3452 [00:28<00:30, 57.73it/s]\u001b[A\u001b[A\n\n 49%|████▉     | 1693/3452 [00:29<00:31, 56.22it/s]\u001b[A\u001b[A\n\n 49%|████▉     | 1699/3452 [00:29<00:30, 56.81it/s]\u001b[A\u001b[A\n\n 49%|████▉     | 1705/3452 [00:29<00:34, 51.26it/s]\u001b[A\u001b[A\n\n 50%|████▉     | 1711/3452 [00:29<00:34, 50.74it/s]\u001b[A\u001b[A\n\n 50%|████▉     | 1718/3452 [00:29<00:31, 55.01it/s]\u001b[A\u001b[A\n\n 50%|████▉     | 1724/3452 [00:29<00:32, 53.96it/s]\u001b[A\u001b[A\n\n 50%|█████     | 1731/3452 [00:29<00:30, 55.91it/s]\u001b[A\u001b[A\n\n 50%|█████     | 1737/3452 [00:29<00:35, 48.06it/s]\u001b[A\u001b[A\n\n 50%|█████     | 1743/3452 [00:30<00:33, 50.48it/s]\u001b[A\u001b[A\n\n 51%|█████     | 1749/3452 [00:30<00:33, 50.14it/s]\u001b[A\u001b[A\n\n 51%|█████     | 1755/3452 [00:30<00:32, 51.58it/s]\u001b[A\u001b[A\n\n 51%|█████     | 1761/3452 [00:30<00:32, 51.53it/s]\u001b[A\u001b[A\n\n 51%|█████     | 1767/3452 [00:30<00:32, 51.70it/s]\u001b[A\u001b[A\n\n 51%|█████▏    | 1774/3452 [00:30<00:31, 53.34it/s]\u001b[A\u001b[A\n\n 52%|█████▏    | 1780/3452 [00:30<00:31, 53.15it/s]\u001b[A\u001b[A\n\n 52%|█████▏    | 1786/3452 [00:30<00:31, 53.17it/s]\u001b[A\u001b[A\n\n 52%|█████▏    | 1792/3452 [00:30<00:30, 54.53it/s]\u001b[A\u001b[A\n\n 52%|█████▏    | 1799/3452 [00:31<00:28, 57.35it/s]\u001b[A\u001b[A\n\n 52%|█████▏    | 1805/3452 [00:31<00:28, 57.19it/s]\u001b[A\u001b[A\n\n 52%|█████▏    | 1811/3452 [00:31<00:30, 53.58it/s]\u001b[A\u001b[A\n\n 53%|█████▎    | 1817/3452 [00:31<00:29, 55.02it/s]\u001b[A\u001b[A\n\n 53%|█████▎    | 1823/3452 [00:31<00:31, 52.26it/s]\u001b[A\u001b[A\n\n 53%|█████▎    | 1829/3452 [00:31<00:31, 50.86it/s]\u001b[A\u001b[A\n\n 53%|█████▎    | 1836/3452 [00:31<00:29, 54.15it/s]\u001b[A\u001b[A\n\n 53%|█████▎    | 1844/3452 [00:31<00:26, 60.42it/s]\u001b[A\u001b[A\n\n 54%|█████▎    | 1851/3452 [00:31<00:26, 59.44it/s]\u001b[A\u001b[A\n\n 54%|█████▍    | 1858/3452 [00:32<00:25, 61.42it/s]\u001b[A\u001b[A\n\n 54%|█████▍    | 1865/3452 [00:32<00:26, 59.43it/s]\u001b[A\u001b[A\n\n 54%|█████▍    | 1872/3452 [00:32<00:25, 60.90it/s]\u001b[A\u001b[A\n\n 54%|█████▍    | 1879/3452 [00:32<00:25, 62.58it/s]\u001b[A\u001b[A\n\n 55%|█████▍    | 1886/3452 [00:32<00:25, 62.37it/s]\u001b[A\u001b[A\n\n 55%|█████▍    | 1893/3452 [00:32<00:28, 54.90it/s]\u001b[A\u001b[A\n\n 55%|█████▌    | 1901/3452 [00:32<00:25, 60.23it/s]\u001b[A\u001b[A\n\n 55%|█████▌    | 1908/3452 [00:32<00:27, 56.97it/s]\u001b[A\u001b[A\n\n 55%|█████▌    | 1915/3452 [00:33<00:26, 58.89it/s]\u001b[A\u001b[A\n\n 56%|█████▌    | 1922/3452 [00:33<00:26, 56.78it/s]\u001b[A\u001b[A\n\n 56%|█████▌    | 1929/3452 [00:33<00:26, 58.18it/s]\u001b[A\u001b[A\n\n 56%|█████▌    | 1935/3452 [00:33<00:25, 58.59it/s]\u001b[A\u001b[A\n\n 56%|█████▌    | 1941/3452 [00:33<00:26, 58.00it/s]\u001b[A\u001b[A\n\n 56%|█████▋    | 1947/3452 [00:33<00:25, 57.89it/s]\u001b[A\u001b[A\n\n 57%|█████▋    | 1953/3452 [00:33<00:26, 57.01it/s]\u001b[A\u001b[A\n\n 57%|█████▋    | 1959/3452 [00:33<00:26, 55.49it/s]\u001b[A\u001b[A\n\n 57%|█████▋    | 1965/3452 [00:33<00:28, 51.57it/s]\u001b[A\u001b[A\n\n 57%|█████▋    | 1973/3452 [00:34<00:25, 57.79it/s]\u001b[A\u001b[A\n\n 57%|█████▋    | 1980/3452 [00:34<00:24, 59.50it/s]\u001b[A\u001b[A\n\n 58%|█████▊    | 1987/3452 [00:34<00:26, 55.93it/s]\u001b[A\u001b[A\n\n 58%|█████▊    | 1994/3452 [00:34<00:25, 58.08it/s]\u001b[A\u001b[A\n\n 58%|█████▊    | 2001/3452 [00:34<00:24, 59.09it/s]\u001b[A\u001b[A\n\n 58%|█████▊    | 2008/3452 [00:34<00:25, 57.68it/s]\u001b[A\u001b[A\n\n 58%|█████▊    | 2014/3452 [00:34<00:24, 58.23it/s]\u001b[A\u001b[A\n\n 59%|█████▊    | 2022/3452 [00:34<00:23, 61.75it/s]\u001b[A\u001b[A\n\n 59%|█████▉    | 2029/3452 [00:35<00:23, 61.26it/s]\u001b[A\u001b[A\n\n 59%|█████▉    | 2036/3452 [00:35<00:24, 58.12it/s]\u001b[A\u001b[A\n\n 59%|█████▉    | 2042/3452 [00:35<00:26, 53.96it/s]\u001b[A\u001b[A\n\n 59%|█████▉    | 2048/3452 [00:35<00:27, 51.85it/s]\u001b[A\u001b[A\n\n 60%|█████▉    | 2056/3452 [00:35<00:23, 58.63it/s]\u001b[A\u001b[A\n\n 60%|█████▉    | 2063/3452 [00:35<00:24, 56.51it/s]\u001b[A\u001b[A\n\n 60%|██████    | 2072/3452 [00:35<00:21, 63.48it/s]\u001b[A\u001b[A\n\n 60%|██████    | 2079/3452 [00:35<00:24, 57.14it/s]\u001b[A\u001b[A\n\n 60%|██████    | 2087/3452 [00:36<00:22, 59.88it/s]\u001b[A\u001b[A\n\n 61%|██████    | 2094/3452 [00:36<00:23, 58.40it/s]\u001b[A\u001b[A\n\n 61%|██████    | 2100/3452 [00:36<00:23, 56.94it/s]\u001b[A\u001b[A\n\n 61%|██████    | 2106/3452 [00:36<00:24, 55.83it/s]\u001b[A\u001b[A\n\n 61%|██████    | 2113/3452 [00:36<00:23, 56.50it/s]\u001b[A\u001b[A\n\n 61%|██████▏   | 2119/3452 [00:36<00:24, 55.53it/s]\u001b[A\u001b[A\n\n 62%|██████▏   | 2126/3452 [00:36<00:23, 56.55it/s]\u001b[A\u001b[A\n\n 62%|██████▏   | 2135/3452 [00:36<00:20, 63.91it/s]\u001b[A\u001b[A\n\n 62%|██████▏   | 2142/3452 [00:36<00:20, 65.41it/s]\u001b[A\u001b[A\n\n 62%|██████▏   | 2149/3452 [00:37<00:20, 64.58it/s]\u001b[A\u001b[A\n\n 62%|██████▏   | 2156/3452 [00:37<00:22, 58.31it/s]\u001b[A\u001b[A\n\n 63%|██████▎   | 2163/3452 [00:37<00:21, 60.69it/s]\u001b[A\u001b[A\n\n 63%|██████▎   | 2170/3452 [00:37<00:20, 62.02it/s]\u001b[A\u001b[A\n\n 63%|██████▎   | 2177/3452 [00:37<00:22, 57.73it/s]\u001b[A\u001b[A\n\n 63%|██████▎   | 2183/3452 [00:37<00:22, 56.84it/s]\u001b[A\u001b[A\n\n 63%|██████▎   | 2189/3452 [00:37<00:22, 56.53it/s]\u001b[A\u001b[A\n\n 64%|██████▎   | 2195/3452 [00:37<00:22, 56.40it/s]\u001b[A\u001b[A\n\n 64%|██████▍   | 2202/3452 [00:38<00:21, 58.39it/s]\u001b[A\u001b[A\n\n 64%|██████▍   | 2208/3452 [00:38<00:22, 55.23it/s]\u001b[A\u001b[A\n\n 64%|██████▍   | 2214/3452 [00:38<00:22, 54.17it/s]\u001b[A\u001b[A\n\n 64%|██████▍   | 2222/3452 [00:38<00:20, 59.27it/s]\u001b[A\u001b[A\n\n 65%|██████▍   | 2229/3452 [00:38<00:20, 60.40it/s]\u001b[A\u001b[A\n\n 65%|██████▍   | 2238/3452 [00:38<00:18, 66.89it/s]\u001b[A\u001b[A\n\n 65%|██████▌   | 2246/3452 [00:38<00:17, 68.72it/s]\u001b[A\u001b[A\n\n 65%|██████▌   | 2253/3452 [00:38<00:18, 64.37it/s]\u001b[A\u001b[A\n\n 65%|██████▌   | 2260/3452 [00:38<00:19, 62.34it/s]\u001b[A\u001b[A\n\n 66%|██████▌   | 2267/3452 [00:39<00:19, 60.56it/s]\u001b[A\u001b[A\n\n 66%|██████▌   | 2274/3452 [00:39<00:19, 59.24it/s]\u001b[A\u001b[A\n\n 66%|██████▌   | 2281/3452 [00:39<00:18, 61.93it/s]\u001b[A\u001b[A\n\n 66%|██████▋   | 2288/3452 [00:39<00:18, 62.21it/s]\u001b[A\u001b[A\n\n 66%|██████▋   | 2295/3452 [00:39<00:18, 63.20it/s]\u001b[A\u001b[A\n\n 67%|██████▋   | 2302/3452 [00:39<00:18, 60.77it/s]\u001b[A\u001b[A\n\n 67%|██████▋   | 2310/3452 [00:39<00:17, 65.34it/s]\u001b[A\u001b[A\n\n 67%|██████▋   | 2317/3452 [00:39<00:18, 62.87it/s]\u001b[A\u001b[A\n\n 67%|██████▋   | 2324/3452 [00:39<00:19, 57.13it/s]\u001b[A\u001b[A\n\n 68%|██████▊   | 2331/3452 [00:40<00:18, 59.10it/s]\u001b[A\u001b[A\n\n 68%|██████▊   | 2338/3452 [00:40<00:18, 60.02it/s]\u001b[A\u001b[A\n\n 68%|██████▊   | 2345/3452 [00:40<00:17, 61.56it/s]\u001b[A\u001b[A\n\n 68%|██████▊   | 2352/3452 [00:40<00:17, 62.04it/s]\u001b[A\u001b[A\n\n 68%|██████▊   | 2359/3452 [00:40<00:17, 62.77it/s]\u001b[A\u001b[A\n\n 69%|██████▊   | 2366/3452 [00:40<00:16, 63.89it/s]\u001b[A\u001b[A\n\n 69%|██████▊   | 2373/3452 [00:40<00:19, 55.87it/s]\u001b[A\u001b[A\n\n 69%|██████▉   | 2379/3452 [00:40<00:19, 56.16it/s]\u001b[A\u001b[A\n\n 69%|██████▉   | 2385/3452 [00:41<00:18, 56.39it/s]\u001b[A\u001b[A\n\n 69%|██████▉   | 2391/3452 [00:41<00:19, 54.81it/s]\u001b[A\u001b[A\n\n 69%|██████▉   | 2398/3452 [00:41<00:18, 56.10it/s]\u001b[A\u001b[A\n\n 70%|██████▉   | 2404/3452 [00:41<00:18, 56.60it/s]\u001b[A\u001b[A\n\n 70%|██████▉   | 2411/3452 [00:41<00:17, 58.46it/s]\u001b[A\u001b[A\n\n 70%|███████   | 2417/3452 [00:41<00:18, 56.77it/s]\u001b[A\u001b[A\n\n 70%|███████   | 2424/3452 [00:41<00:17, 59.94it/s]\u001b[A\u001b[A\n\n 70%|███████   | 2431/3452 [00:41<00:17, 59.55it/s]\u001b[A\u001b[A\n\n 71%|███████   | 2437/3452 [00:41<00:18, 54.11it/s]\u001b[A\u001b[A\n\n 71%|███████   | 2443/3452 [00:42<00:19, 52.10it/s]\u001b[A\u001b[A\n\n 71%|███████   | 2450/3452 [00:42<00:18, 53.58it/s]\u001b[A\u001b[A\n\n 71%|███████   | 2456/3452 [00:42<00:18, 53.82it/s]\u001b[A\u001b[A\n\n 71%|███████▏  | 2462/3452 [00:42<00:18, 54.42it/s]\u001b[A\u001b[A\n\n 72%|███████▏  | 2469/3452 [00:42<00:17, 57.19it/s]\u001b[A\u001b[A\n\n 72%|███████▏  | 2476/3452 [00:42<00:16, 59.09it/s]\u001b[A\u001b[A\n\n 72%|███████▏  | 2482/3452 [00:42<00:17, 56.29it/s]\u001b[A\u001b[A\n\n 72%|███████▏  | 2489/3452 [00:42<00:16, 57.99it/s]\u001b[A\u001b[A\n\n 72%|███████▏  | 2495/3452 [00:42<00:17, 54.22it/s]\u001b[A\u001b[A\n\n 72%|███████▏  | 2502/3452 [00:43<00:16, 58.39it/s]\u001b[A\u001b[A\n\n 73%|███████▎  | 2508/3452 [00:43<00:17, 54.93it/s]\u001b[A\u001b[A\n\n 73%|███████▎  | 2514/3452 [00:43<00:17, 54.29it/s]\u001b[A\u001b[A\n\n 73%|███████▎  | 2521/3452 [00:43<00:16, 56.08it/s]\u001b[A\u001b[A\n\n 73%|███████▎  | 2528/3452 [00:43<00:16, 56.04it/s]\u001b[A\u001b[A\n\n 73%|███████▎  | 2534/3452 [00:43<00:16, 55.68it/s]\u001b[A\u001b[A\n\n 74%|███████▎  | 2542/3452 [00:43<00:15, 60.35it/s]\u001b[A\u001b[A\n\n 74%|███████▍  | 2549/3452 [00:43<00:14, 62.07it/s]\u001b[A\u001b[A\n\n 74%|███████▍  | 2556/3452 [00:44<00:15, 58.99it/s]\u001b[A\u001b[A\n\n 74%|███████▍  | 2564/3452 [00:44<00:13, 63.90it/s]\u001b[A\u001b[A\n\n 74%|███████▍  | 2571/3452 [00:44<00:14, 59.96it/s]\u001b[A\u001b[A\n\n 75%|███████▍  | 2578/3452 [00:44<00:14, 61.56it/s]\u001b[A\u001b[A\n\n 75%|███████▍  | 2585/3452 [00:44<00:14, 61.80it/s]\u001b[A\u001b[A\n\n 75%|███████▌  | 2592/3452 [00:44<00:14, 60.73it/s]\u001b[A\u001b[A\n\n 75%|███████▌  | 2599/3452 [00:44<00:14, 59.03it/s]\u001b[A\u001b[A\n\n 75%|███████▌  | 2605/3452 [00:44<00:14, 57.15it/s]\u001b[A\u001b[A\n\n 76%|███████▌  | 2612/3452 [00:44<00:14, 57.78it/s]\u001b[A\u001b[A\n\n 76%|███████▌  | 2618/3452 [00:45<00:14, 56.45it/s]\u001b[A\u001b[A\n\n 76%|███████▌  | 2624/3452 [00:45<00:14, 56.56it/s]\u001b[A\u001b[A\n\n 76%|███████▌  | 2631/3452 [00:45<00:13, 58.75it/s]\u001b[A\u001b[A\n\n 76%|███████▋  | 2637/3452 [00:45<00:14, 57.44it/s]\u001b[A\u001b[A\n\n 77%|███████▋  | 2645/3452 [00:45<00:13, 60.38it/s]\u001b[A\u001b[A\n\n 77%|███████▋  | 2652/3452 [00:45<00:13, 58.96it/s]\u001b[A\u001b[A\n\n 77%|███████▋  | 2658/3452 [00:45<00:13, 58.90it/s]\u001b[A\u001b[A\n\n 77%|███████▋  | 2664/3452 [00:45<00:13, 58.79it/s]\u001b[A\u001b[A\n\n 77%|███████▋  | 2672/3452 [00:45<00:12, 63.61it/s]\u001b[A\u001b[A\n\n 78%|███████▊  | 2679/3452 [00:46<00:12, 59.64it/s]\u001b[A\u001b[A\n\n 78%|███████▊  | 2686/3452 [00:46<00:13, 58.13it/s]\u001b[A\u001b[A\n\n 78%|███████▊  | 2692/3452 [00:46<00:13, 57.27it/s]\u001b[A\u001b[A\n\n 78%|███████▊  | 2700/3452 [00:46<00:12, 60.74it/s]\u001b[A\u001b[A\n\n 78%|███████▊  | 2707/3452 [00:46<00:11, 62.21it/s]\u001b[A\u001b[A\n\n 79%|███████▊  | 2714/3452 [00:46<00:11, 62.42it/s]\u001b[A\u001b[A\n\n 79%|███████▉  | 2721/3452 [00:46<00:11, 61.67it/s]\u001b[A\u001b[A\n\n 79%|███████▉  | 2728/3452 [00:46<00:12, 59.97it/s]\u001b[A\u001b[A\n\n 79%|███████▉  | 2735/3452 [00:47<00:12, 58.32it/s]\u001b[A\u001b[A\n\n 79%|███████▉  | 2741/3452 [00:47<00:12, 54.92it/s]\u001b[A\u001b[A\n\n 80%|███████▉  | 2748/3452 [00:47<00:12, 57.62it/s]\u001b[A\u001b[A\n\n 80%|███████▉  | 2756/3452 [00:47<00:11, 62.51it/s]\u001b[A\u001b[A\n\n 80%|████████  | 2763/3452 [00:47<00:11, 58.33it/s]\u001b[A\u001b[A\n\n 80%|████████  | 2769/3452 [00:47<00:12, 54.49it/s]\u001b[A\u001b[A\n\n 80%|████████  | 2777/3452 [00:47<00:11, 58.85it/s]\u001b[A\u001b[A\n\n 81%|████████  | 2783/3452 [00:47<00:11, 57.63it/s]\u001b[A\u001b[A\n\n 81%|████████  | 2791/3452 [00:47<00:10, 62.67it/s]\u001b[A\u001b[A\n\n 81%|████████  | 2799/3452 [00:48<00:10, 64.77it/s]\u001b[A\u001b[A\n\n 81%|████████▏ | 2806/3452 [00:48<00:10, 60.63it/s]\u001b[A\u001b[A\n\n 82%|████████▏ | 2814/3452 [00:48<00:09, 65.06it/s]\u001b[A\u001b[A\n\n 82%|████████▏ | 2821/3452 [00:48<00:09, 63.97it/s]\u001b[A\u001b[A\n\n 82%|████████▏ | 2828/3452 [00:48<00:10, 61.55it/s]\u001b[A\u001b[A\n\n 82%|████████▏ | 2835/3452 [00:48<00:10, 59.52it/s]\u001b[A\u001b[A\n\n 82%|████████▏ | 2842/3452 [00:48<00:09, 61.42it/s]\u001b[A\u001b[A\n\n 83%|████████▎ | 2852/3452 [00:48<00:08, 69.44it/s]\u001b[A\u001b[A\n\n 83%|████████▎ | 2860/3452 [00:49<00:09, 63.65it/s]\u001b[A\u001b[A\n\n 83%|████████▎ | 2867/3452 [00:49<00:09, 62.48it/s]\u001b[A\u001b[A\n\n 83%|████████▎ | 2874/3452 [00:49<00:10, 56.36it/s]\u001b[A\u001b[A\n\n 83%|████████▎ | 2880/3452 [00:49<00:10, 56.13it/s]\u001b[A\u001b[A\n\n 84%|████████▎ | 2886/3452 [00:49<00:10, 54.97it/s]\u001b[A\u001b[A\n\n 84%|████████▍ | 2892/3452 [00:49<00:10, 52.32it/s]\u001b[A\u001b[A\n\n 84%|████████▍ | 2898/3452 [00:49<00:10, 53.44it/s]\u001b[A\u001b[A\n\n 84%|████████▍ | 2905/3452 [00:49<00:09, 57.68it/s]\u001b[A\u001b[A\n\n 84%|████████▍ | 2913/3452 [00:50<00:08, 60.23it/s]\u001b[A\u001b[A\n\n 85%|████████▍ | 2920/3452 [00:50<00:08, 60.13it/s]\u001b[A\u001b[A\n\n 85%|████████▍ | 2928/3452 [00:50<00:08, 65.14it/s]\u001b[A\u001b[A\n\n 85%|████████▌ | 2935/3452 [00:50<00:08, 61.97it/s]\u001b[A\u001b[A\n\n 85%|████████▌ | 2942/3452 [00:50<00:08, 61.36it/s]\u001b[A\u001b[A\n\n 85%|████████▌ | 2949/3452 [00:50<00:08, 61.45it/s]\u001b[A\u001b[A\n\n 86%|████████▌ | 2956/3452 [00:50<00:08, 60.56it/s]\u001b[A\u001b[A\n\n 86%|████████▌ | 2963/3452 [00:50<00:08, 58.79it/s]\u001b[A\u001b[A\n\n 86%|████████▌ | 2970/3452 [00:50<00:08, 57.43it/s]\u001b[A\u001b[A\n\n 86%|████████▌ | 2977/3452 [00:51<00:07, 60.17it/s]\u001b[A\u001b[A\n\n 86%|████████▋ | 2984/3452 [00:51<00:07, 62.32it/s]\u001b[A\u001b[A\n\n 87%|████████▋ | 2991/3452 [00:51<00:07, 63.62it/s]\u001b[A\u001b[A\n\n 87%|████████▋ | 2998/3452 [00:51<00:07, 63.20it/s]\u001b[A\u001b[A\n\n 87%|████████▋ | 3005/3452 [00:51<00:07, 60.56it/s]\u001b[A\u001b[A\n\n 87%|████████▋ | 3012/3452 [00:51<00:07, 59.12it/s]\u001b[A\u001b[A\n\n 87%|████████▋ | 3019/3452 [00:51<00:07, 61.67it/s]\u001b[A\u001b[A\n\n 88%|████████▊ | 3026/3452 [00:51<00:06, 61.07it/s]\u001b[A\u001b[A\n\n 88%|████████▊ | 3033/3452 [00:51<00:06, 62.27it/s]\u001b[A\u001b[A\n\n 88%|████████▊ | 3040/3452 [00:52<00:06, 59.74it/s]\u001b[A\u001b[A\n\n 88%|████████▊ | 3047/3452 [00:52<00:06, 59.16it/s]\u001b[A\u001b[A\n\n 88%|████████▊ | 3054/3452 [00:52<00:06, 60.79it/s]\u001b[A\u001b[A\n\n 89%|████████▊ | 3061/3452 [00:52<00:06, 58.42it/s]\u001b[A\u001b[A\n\n 89%|████████▉ | 3067/3452 [00:52<00:06, 57.59it/s]\u001b[A\u001b[A\n\n 89%|████████▉ | 3073/3452 [00:52<00:06, 54.97it/s]\u001b[A\u001b[A\n\n 89%|████████▉ | 3080/3452 [00:52<00:06, 57.93it/s]\u001b[A\u001b[A\n\n 89%|████████▉ | 3088/3452 [00:52<00:06, 60.11it/s]\u001b[A\u001b[A\n\n 90%|████████▉ | 3095/3452 [00:53<00:05, 59.79it/s]\u001b[A\u001b[A\n\n 90%|████████▉ | 3102/3452 [00:53<00:05, 60.51it/s]\u001b[A\u001b[A\n\n 90%|█████████ | 3109/3452 [00:53<00:05, 60.80it/s]\u001b[A\u001b[A\n\n 90%|█████████ | 3116/3452 [00:53<00:05, 57.18it/s]\u001b[A\u001b[A\n\n 90%|█████████ | 3122/3452 [00:53<00:05, 57.14it/s]\u001b[A\u001b[A\n\n 91%|█████████ | 3130/3452 [00:53<00:05, 60.48it/s]\u001b[A\u001b[A\n\n 91%|█████████ | 3137/3452 [00:53<00:05, 56.29it/s]\u001b[A\u001b[A\n\n 91%|█████████ | 3146/3452 [00:53<00:04, 62.35it/s]\u001b[A\u001b[A\n\n 91%|█████████▏| 3154/3452 [00:53<00:04, 66.22it/s]\u001b[A\u001b[A\n\n 92%|█████████▏| 3161/3452 [00:54<00:04, 62.73it/s]\u001b[A\u001b[A\n\n 92%|█████████▏| 3168/3452 [00:54<00:04, 64.51it/s]\u001b[A\u001b[A\n\n 92%|█████████▏| 3175/3452 [00:54<00:04, 63.24it/s]\u001b[A\u001b[A\n\n 92%|█████████▏| 3182/3452 [00:54<00:04, 57.13it/s]\u001b[A\u001b[A\n\n 92%|█████████▏| 3188/3452 [00:54<00:04, 54.96it/s]\u001b[A\u001b[A\n\n 93%|█████████▎| 3194/3452 [00:54<00:04, 52.88it/s]\u001b[A\u001b[A\n\n 93%|█████████▎| 3200/3452 [00:54<00:04, 52.89it/s]\u001b[A\u001b[A\n\n 93%|█████████▎| 3208/3452 [00:54<00:04, 58.66it/s]\u001b[A\u001b[A\n\n 93%|█████████▎| 3214/3452 [00:55<00:04, 55.43it/s]\u001b[A\u001b[A\n\n 93%|█████████▎| 3220/3452 [00:55<00:04, 55.01it/s]\u001b[A\u001b[A\n\n 93%|█████████▎| 3226/3452 [00:55<00:04, 55.95it/s]\u001b[A\u001b[A\n\n 94%|█████████▎| 3234/3452 [00:55<00:03, 59.99it/s]\u001b[A\u001b[A\n\n 94%|█████████▍| 3241/3452 [00:55<00:03, 60.05it/s]\u001b[A\u001b[A\n\n 94%|█████████▍| 3248/3452 [00:55<00:03, 61.36it/s]\u001b[A\u001b[A\n\n 94%|█████████▍| 3256/3452 [00:55<00:03, 64.58it/s]\u001b[A\u001b[A\n\n 95%|█████████▍| 3263/3452 [00:55<00:02, 65.91it/s]\u001b[A\u001b[A\n\n 95%|█████████▍| 3270/3452 [00:55<00:02, 63.08it/s]\u001b[A\u001b[A\n\n 95%|█████████▍| 3277/3452 [00:56<00:02, 62.67it/s]\u001b[A\u001b[A\n\n 95%|█████████▌| 3284/3452 [00:56<00:02, 61.22it/s]\u001b[A\u001b[A\n\n 95%|█████████▌| 3291/3452 [00:56<00:02, 58.67it/s]\u001b[A\u001b[A\n\n 96%|█████████▌| 3297/3452 [00:56<00:02, 58.38it/s]\u001b[A\u001b[A\n\n 96%|█████████▌| 3303/3452 [00:56<00:02, 57.63it/s]\u001b[A\u001b[A\n\n 96%|█████████▌| 3309/3452 [00:56<00:02, 56.14it/s]\u001b[A\u001b[A\n\n 96%|█████████▌| 3317/3452 [00:56<00:02, 60.80it/s]\u001b[A\u001b[A\n\n 96%|█████████▋| 3324/3452 [00:56<00:02, 62.03it/s]\u001b[A\u001b[A\n\n 96%|█████████▋| 3331/3452 [00:56<00:01, 62.69it/s]\u001b[A\u001b[A\n\n 97%|█████████▋| 3338/3452 [00:57<00:01, 62.02it/s]\u001b[A\u001b[A\n\n 97%|█████████▋| 3345/3452 [00:57<00:01, 59.59it/s]\u001b[A\u001b[A\n\n 97%|█████████▋| 3351/3452 [00:57<00:01, 56.81it/s]\u001b[A\u001b[A\n\n 97%|█████████▋| 3358/3452 [00:57<00:01, 57.25it/s]\u001b[A\u001b[A\n\n 98%|█████████▊| 3366/3452 [00:57<00:01, 60.11it/s]\u001b[A\u001b[A\n\n 98%|█████████▊| 3373/3452 [00:57<00:01, 56.76it/s]\u001b[A\u001b[A\n\n 98%|█████████▊| 3380/3452 [00:57<00:01, 58.76it/s]\u001b[A\u001b[A\n\n 98%|█████████▊| 3386/3452 [00:57<00:01, 57.77it/s]\u001b[A\u001b[A\n\n 98%|█████████▊| 3392/3452 [00:58<00:01, 56.61it/s]\u001b[A\u001b[A\n\n 99%|█████████▊| 3402/3452 [00:58<00:00, 65.57it/s]\u001b[A\u001b[A\n\n 99%|█████████▉| 3409/3452 [00:58<00:00, 66.01it/s]\u001b[A\u001b[A\n\n 99%|█████████▉| 3416/3452 [00:58<00:00, 59.81it/s]\u001b[A\u001b[A\n\n 99%|█████████▉| 3423/3452 [00:58<00:00, 60.97it/s]\u001b[A\u001b[A\n\n 99%|█████████▉| 3430/3452 [00:58<00:00, 58.23it/s]\u001b[A\u001b[A\n\n100%|█████████▉| 3437/3452 [00:58<00:00, 60.15it/s]\u001b[A\u001b[A\n\n100%|█████████▉| 3444/3452 [00:58<00:00, 52.84it/s]\u001b[A\u001b[A\n\n100%|██████████| 3452/3452 [00:59<00:00, 58.42it/s]\u001b[A\u001b[A\n\n\n  0%|          | 0/826 [00:00<?, ?it/s]\u001b[A\u001b[A\n\n  1%|          | 7/826 [00:00<00:11, 68.27it/s]\u001b[A\u001b[A\n\n  2%|▏         | 14/826 [00:00<00:12, 66.88it/s]\u001b[A\u001b[A\n\n  3%|▎         | 22/826 [00:00<00:11, 71.67it/s]\u001b[A\u001b[A\n\n  4%|▎         | 30/826 [00:00<00:12, 61.99it/s]\u001b[A\u001b[A\n\n  4%|▍         | 37/826 [00:00<00:12, 61.22it/s]\u001b[A\u001b[A\n\n  5%|▌         | 44/826 [00:00<00:14, 54.21it/s]\u001b[A\u001b[A\n\n  6%|▌         | 50/826 [00:00<00:14, 54.81it/s]\u001b[A\u001b[A\n\n  7%|▋         | 58/826 [00:00<00:12, 61.44it/s]\u001b[A\u001b[A\n\n  8%|▊         | 65/826 [00:01<00:13, 58.36it/s]\u001b[A\u001b[A\n\n  9%|▊         | 71/826 [00:01<00:13, 57.94it/s]\u001b[A\u001b[A\n\n  9%|▉         | 77/826 [00:01<00:13, 56.90it/s]\u001b[A\u001b[A\n\n 10%|█         | 83/826 [00:01<00:13, 55.03it/s]\u001b[A\u001b[A\n\n 11%|█         | 89/826 [00:01<00:13, 55.80it/s]\u001b[A\u001b[A\n\n 12%|█▏        | 95/826 [00:01<00:14, 51.23it/s]\u001b[A\u001b[A\n\n 12%|█▏        | 101/826 [00:01<00:14, 49.30it/s]\u001b[A\u001b[A\n\n 13%|█▎        | 107/826 [00:01<00:14, 49.52it/s]\u001b[A\u001b[A\n\n 14%|█▎        | 113/826 [00:02<00:13, 51.69it/s]\u001b[A\u001b[A\n\n 14%|█▍        | 119/826 [00:02<00:13, 51.09it/s]\u001b[A\u001b[A\n\n 15%|█▌        | 127/826 [00:02<00:12, 56.22it/s]\u001b[A\u001b[A\n\n 16%|█▌        | 133/826 [00:02<00:12, 56.24it/s]\u001b[A\u001b[A\n\n 17%|█▋        | 139/826 [00:02<00:12, 54.01it/s]\u001b[A\u001b[A\n\n 18%|█▊        | 145/826 [00:02<00:13, 52.23it/s]\u001b[A\u001b[A\n\n 18%|█▊        | 152/826 [00:02<00:11, 56.85it/s]\u001b[A\u001b[A\n\n 19%|█▉        | 159/826 [00:02<00:11, 59.81it/s]\u001b[A\u001b[A\n\n 20%|██        | 166/826 [00:02<00:10, 60.86it/s]\u001b[A\u001b[A\n\n 21%|██        | 173/826 [00:03<00:10, 59.69it/s]\u001b[A\u001b[A\n\n 22%|██▏       | 181/826 [00:03<00:10, 63.44it/s]\u001b[A\u001b[A\n\n 23%|██▎       | 188/826 [00:03<00:10, 62.89it/s]\u001b[A\u001b[A\n\n 24%|██▎       | 195/826 [00:03<00:10, 60.67it/s]\u001b[A\u001b[A\n\n 25%|██▍       | 203/826 [00:03<00:09, 63.33it/s]\u001b[A\u001b[A\n\n 25%|██▌       | 210/826 [00:03<00:09, 62.91it/s]\u001b[A\u001b[A\n\n 26%|██▋       | 217/826 [00:03<00:09, 64.51it/s]\u001b[A\u001b[A\n\n 27%|██▋       | 224/826 [00:03<00:10, 58.63it/s]\u001b[A\u001b[A\n\n 28%|██▊       | 231/826 [00:03<00:10, 58.75it/s]\u001b[A\u001b[A\n\n 29%|██▊       | 237/826 [00:04<00:10, 58.13it/s]\u001b[A\u001b[A\n\n 29%|██▉       | 243/826 [00:04<00:10, 56.81it/s]\u001b[A\u001b[A\n\n 30%|███       | 251/826 [00:04<00:09, 59.73it/s]\u001b[A\u001b[A\n\n 31%|███       | 257/826 [00:04<00:09, 59.01it/s]\u001b[A\u001b[A\n\n 32%|███▏      | 265/826 [00:04<00:09, 62.18it/s]\u001b[A\u001b[A\n\n 33%|███▎      | 273/826 [00:04<00:08, 64.52it/s]\u001b[A\u001b[A\n\n 34%|███▍      | 280/826 [00:04<00:09, 60.19it/s]\u001b[A\u001b[A\n\n 35%|███▍      | 287/826 [00:04<00:09, 56.46it/s]\u001b[A\u001b[A\n\n 36%|███▌      | 294/826 [00:05<00:09, 57.55it/s]\u001b[A\u001b[A\n\n 36%|███▋      | 300/826 [00:05<00:09, 57.49it/s]\u001b[A\u001b[A\n\n 37%|███▋      | 306/826 [00:05<00:09, 57.54it/s]\u001b[A\u001b[A\n\n 38%|███▊      | 313/826 [00:05<00:08, 57.55it/s]\u001b[A\u001b[A\n\n 39%|███▊      | 319/826 [00:05<00:09, 56.00it/s]\u001b[A\u001b[A\n\n 39%|███▉      | 325/826 [00:05<00:09, 52.80it/s]\u001b[A\u001b[A\n\n 40%|████      | 331/826 [00:05<00:09, 52.59it/s]\u001b[A\u001b[A\n\n 41%|████      | 337/826 [00:05<00:09, 52.60it/s]\u001b[A\u001b[A\n\n 42%|████▏     | 343/826 [00:05<00:09, 51.29it/s]\u001b[A\u001b[A\n\n 42%|████▏     | 349/826 [00:06<00:09, 51.97it/s]\u001b[A\u001b[A\n\n 43%|████▎     | 355/826 [00:06<00:09, 51.90it/s]\u001b[A\u001b[A\n\n 44%|████▍     | 363/826 [00:06<00:08, 56.06it/s]\u001b[A\u001b[A\n\n 45%|████▍     | 369/826 [00:06<00:08, 54.84it/s]\u001b[A\u001b[A\n\n 46%|████▌     | 376/826 [00:06<00:07, 56.30it/s]\u001b[A\u001b[A\n\n 46%|████▌     | 382/826 [00:06<00:07, 57.00it/s]\u001b[A\u001b[A\n\n 47%|████▋     | 388/826 [00:06<00:08, 51.04it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 394/826 [00:06<00:08, 50.54it/s]\u001b[A\u001b[A\n\n 48%|████▊     | 400/826 [00:07<00:08, 50.43it/s]\u001b[A\u001b[A\n\n 49%|████▉     | 407/826 [00:07<00:07, 54.42it/s]\u001b[A\u001b[A\n\n 50%|█████     | 415/826 [00:07<00:06, 59.69it/s]\u001b[A\u001b[A\n\n 51%|█████     | 422/826 [00:07<00:06, 59.53it/s]\u001b[A\u001b[A\n\n 52%|█████▏    | 429/826 [00:07<00:06, 57.20it/s]\u001b[A\u001b[A\n\n 53%|█████▎    | 435/826 [00:07<00:07, 54.55it/s]\u001b[A\u001b[A\n\n 53%|█████▎    | 441/826 [00:07<00:07, 54.20it/s]\u001b[A\u001b[A\n\n 54%|█████▍    | 448/826 [00:07<00:06, 56.06it/s]\u001b[A\u001b[A\n\n 55%|█████▍    | 454/826 [00:08<00:07, 52.73it/s]\u001b[A\u001b[A\n\n 56%|█████▌    | 461/826 [00:08<00:06, 54.16it/s]\u001b[A\u001b[A\n\n 57%|█████▋    | 469/826 [00:08<00:05, 60.29it/s]\u001b[A\u001b[A\n\n 58%|█████▊    | 476/826 [00:08<00:06, 56.02it/s]\u001b[A\u001b[A\n\n 59%|█████▊    | 484/826 [00:08<00:05, 58.54it/s]\u001b[A\u001b[A\n\n 60%|█████▉    | 493/826 [00:08<00:05, 63.58it/s]\u001b[A\u001b[A\n\n 61%|██████    | 500/826 [00:08<00:05, 58.23it/s]\u001b[A\u001b[A\n\n 62%|██████▏   | 508/826 [00:08<00:05, 62.68it/s]\u001b[A\u001b[A\n\n 62%|██████▏   | 515/826 [00:09<00:05, 56.78it/s]\u001b[A\u001b[A\n\n 63%|██████▎   | 521/826 [00:09<00:05, 57.46it/s]\u001b[A\u001b[A\n\n 64%|██████▍   | 527/826 [00:09<00:05, 55.37it/s]\u001b[A\u001b[A\n\n 65%|██████▍   | 533/826 [00:09<00:05, 55.80it/s]\u001b[A\u001b[A\n\n 65%|██████▌   | 539/826 [00:09<00:05, 56.21it/s]\u001b[A\u001b[A\n\n 66%|██████▌   | 546/826 [00:09<00:04, 56.76it/s]\u001b[A\u001b[A\n\n 67%|██████▋   | 554/826 [00:09<00:04, 59.87it/s]\u001b[A\u001b[A\n\n 68%|██████▊   | 561/826 [00:09<00:04, 59.55it/s]\u001b[A\u001b[A\n\n 69%|██████▉   | 568/826 [00:09<00:04, 61.14it/s]\u001b[A\u001b[A\n\n 70%|██████▉   | 575/826 [00:10<00:04, 62.66it/s]\u001b[A\u001b[A\n\n 71%|███████   | 583/826 [00:10<00:03, 65.63it/s]\u001b[A\u001b[A\n\n 71%|███████▏  | 590/826 [00:10<00:03, 60.42it/s]\u001b[A\u001b[A\n\n 72%|███████▏  | 597/826 [00:10<00:04, 57.13it/s]\u001b[A\u001b[A\n\n 73%|███████▎  | 603/826 [00:10<00:04, 54.94it/s]\u001b[A\u001b[A\n\n 74%|███████▎  | 609/826 [00:10<00:03, 55.70it/s]\u001b[A\u001b[A\n\n 75%|███████▍  | 616/826 [00:10<00:03, 58.41it/s]\u001b[A\u001b[A\n\n 75%|███████▌  | 623/826 [00:10<00:03, 59.94it/s]\u001b[A\u001b[A\n\n 76%|███████▋  | 630/826 [00:11<00:03, 56.82it/s]\u001b[A\u001b[A\n\n 77%|███████▋  | 638/826 [00:11<00:03, 61.48it/s]\u001b[A\u001b[A\n\n 78%|███████▊  | 645/826 [00:11<00:02, 62.16it/s]\u001b[A\u001b[A\n\n 79%|███████▉  | 652/826 [00:11<00:02, 58.90it/s]\u001b[A\u001b[A\n\n 80%|███████▉  | 659/826 [00:11<00:02, 60.55it/s]\u001b[A\u001b[A\n\n 81%|████████  | 666/826 [00:11<00:02, 57.42it/s]\u001b[A\u001b[A\n\n 81%|████████▏ | 672/826 [00:11<00:02, 57.07it/s]\u001b[A\u001b[A\n\n 82%|████████▏ | 678/826 [00:11<00:02, 56.62it/s]\u001b[A\u001b[A\n\n 83%|████████▎ | 684/826 [00:11<00:02, 55.07it/s]\u001b[A\u001b[A\n\n 84%|████████▍ | 692/826 [00:12<00:02, 59.81it/s]\u001b[A\u001b[A\n\n 85%|████████▍ | 699/826 [00:12<00:02, 59.34it/s]\u001b[A\u001b[A\n\n 85%|████████▌ | 705/826 [00:12<00:02, 59.47it/s]\u001b[A\u001b[A\n\n 86%|████████▌ | 712/826 [00:12<00:01, 58.88it/s]\u001b[A\u001b[A\n\n 87%|████████▋ | 718/826 [00:12<00:01, 56.79it/s]\u001b[A\u001b[A\n\n 88%|████████▊ | 727/826 [00:12<00:01, 62.29it/s]\u001b[A\u001b[A\n\n 89%|████████▉ | 734/826 [00:12<00:01, 62.65it/s]\u001b[A\u001b[A\n\n 90%|████████▉ | 742/826 [00:12<00:01, 64.77it/s]\u001b[A\u001b[A\n\n 91%|█████████ | 750/826 [00:12<00:01, 66.52it/s]\u001b[A\u001b[A\n\n 92%|█████████▏| 757/826 [00:13<00:01, 60.56it/s]\u001b[A\u001b[A\n\n 92%|█████████▏| 764/826 [00:13<00:01, 61.46it/s]\u001b[A\u001b[A\n\n 93%|█████████▎| 771/826 [00:13<00:00, 57.86it/s]\u001b[A\u001b[A\n\n 94%|█████████▍| 778/826 [00:13<00:00, 59.80it/s]\u001b[A\u001b[A\n\n 95%|█████████▌| 785/826 [00:13<00:00, 59.13it/s]\u001b[A\u001b[A\n\n 96%|█████████▌| 791/826 [00:13<00:00, 58.21it/s]\u001b[A\u001b[A\n\n 97%|█████████▋| 798/826 [00:13<00:00, 58.34it/s]\u001b[A\u001b[A\n\n 97%|█████████▋| 805/826 [00:13<00:00, 60.44it/s]\u001b[A\u001b[A\n\n 98%|█████████▊| 812/826 [00:14<00:00, 59.93it/s]\u001b[A\u001b[A\n\n 99%|█████████▉| 819/826 [00:14<00:00, 60.49it/s]\u001b[A\u001b[A\n\n100%|██████████| 826/826 [00:14<00:00, 57.92it/s]\u001b[A\u001b[A\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Now, you can use 'text_data' and 'image_data' as inputs to your multimodal model.\n\n# Sample code for creating a multimodal model using TensorFlow/Keras\ntext_input = tf.keras.layers.Input(shape=(max_sequence_length,))\nimage_input = tf.keras.layers.Input(shape=(*image_size, 3))\n\n\n# Define text embedding layer (you can replace this with a more complex text model)\ntext_embedding = tf.keras.layers.Embedding(input_dim=len(word_index) + 1, output_dim=128)(text_input)\ntext_embedding = tf.keras.layers.Flatten()(text_embedding)\n\n# Define image embedding layer using a larger model like InceptionV3\nimage_embedding = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\", input_shape=(299, 299, 3))(image_input)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:19:48.691341Z","iopub.execute_input":"2023-11-18T18:19:48.691748Z","iopub.status.idle":"2023-11-18T18:19:53.366488Z","shell.execute_reply.started":"2023-11-18T18:19:48.691715Z","shell.execute_reply":"2023-11-18T18:19:53.365448Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\n# Concatenate text and image embeddings\ncombined = tf.keras.layers.concatenate([text_embedding, image_embedding])\n\n\n# Add more layers as needed for your specific task\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(combined)\n\nmodel_2 = tf.keras.models.Model(inputs=[text_input, image_input], outputs=output)\n\n# Compile the model\nmodel_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:19:55.756472Z","iopub.execute_input":"2023-11-18T18:19:55.757372Z","iopub.status.idle":"2023-11-18T18:19:55.796966Z","shell.execute_reply.started":"2023-11-18T18:19:55.757333Z","shell.execute_reply":"2023-11-18T18:19:55.796068Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nmodel_2.fit([train_text_data, train_image_data], np.asarray(train_labels), epochs=10, validation_data=([test_text_data,test_image_data],np.asarray(test_labels)))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:23:30.762535Z","iopub.execute_input":"2023-11-18T18:23:30.762922Z","iopub.status.idle":"2023-11-18T18:25:52.751533Z","shell.execute_reply.started":"2023-11-18T18:23:30.762890Z","shell.execute_reply":"2023-11-18T18:25:52.750486Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 1/10\n108/108 [==============================] - 16s 149ms/step - loss: 1.5855 - accuracy: 0.5747 - val_loss: 1.9176 - val_accuracy: 0.6271\nEpoch 2/10\n108/108 [==============================] - 13s 114ms/step - loss: 1.1610 - accuracy: 0.6379 - val_loss: 1.1371 - val_accuracy: 0.6320\nEpoch 3/10\n108/108 [==============================] - 10s 96ms/step - loss: 0.7288 - accuracy: 0.7483 - val_loss: 1.6190 - val_accuracy: 0.5036\nEpoch 4/10\n108/108 [==============================] - 10s 96ms/step - loss: 0.4520 - accuracy: 0.8314 - val_loss: 1.1512 - val_accuracy: 0.6441\nEpoch 5/10\n108/108 [==============================] - 11s 99ms/step - loss: 0.2754 - accuracy: 0.8940 - val_loss: 1.3213 - val_accuracy: 0.5557\nEpoch 6/10\n108/108 [==============================] - 9s 85ms/step - loss: 0.3774 - accuracy: 0.8711 - val_loss: 1.5617 - val_accuracy: 0.5884\nEpoch 7/10\n108/108 [==============================] - 9s 88ms/step - loss: 0.2176 - accuracy: 0.9192 - val_loss: 1.3250 - val_accuracy: 0.6211\nEpoch 8/10\n108/108 [==============================] - 10s 93ms/step - loss: 0.1533 - accuracy: 0.9444 - val_loss: 1.4715 - val_accuracy: 0.6731\nEpoch 9/10\n108/108 [==============================] - 10s 88ms/step - loss: 0.1489 - accuracy: 0.9389 - val_loss: 1.5462 - val_accuracy: 0.6634\nEpoch 10/10\n108/108 [==============================] - 10s 89ms/step - loss: 0.1056 - accuracy: 0.9626 - val_loss: 1.4842 - val_accuracy: 0.6211\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f0e587b5420>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\npredictions = model_2.predict([test_text_data, test_image_data])\npredictions_labels = []\nfor i in predictions:\n    if i >= 0.5:\n        predictions_labels.append(1)\n    else:\n        predictions_labels.append(0)\n\n# Compute the AUROC\nauroc = roc_auc_score(test_labels, predictions_labels)\n\nprint(f'AUROC: {auroc}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:25:55.791869Z","iopub.execute_input":"2023-11-18T18:25:55.792942Z","iopub.status.idle":"2023-11-18T18:25:58.390246Z","shell.execute_reply.started":"2023-11-18T18:25:55.792892Z","shell.execute_reply":"2023-11-18T18:25:58.389332Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"26/26 [==============================] - 2s 69ms/step\nAUROC: 0.5921191553544495\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Compute confusion matrix\ncm = confusion_matrix(test_labels, predictions_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_labels, predictions_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:26:02.473899Z","iopub.execute_input":"2023-11-18T18:26:02.474284Z","iopub.status.idle":"2023-11-18T18:26:02.659655Z","shell.execute_reply.started":"2023-11-18T18:26:02.474253Z","shell.execute_reply":"2023-11-18T18:26:02.658835Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.70      0.70      0.70       520\n           1       0.49      0.48      0.48       306\n\n    accuracy                           0.62       826\n   macro avg       0.59      0.59      0.59       826\nweighted avg       0.62      0.62      0.62       826\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# lets try with another parameters\n\n# Now, you can use 'text_data' and 'image_data' as inputs to your multimodal model.\n\n# Sample code for creating a multimodal model using TensorFlow/Keras\ntext_input = tf.keras.layers.Input(shape=(max_sequence_length,))\nimage_input = tf.keras.layers.Input(shape=(*image_size, 3))\n\n\n# Define text embedding layer (you can replace this with a more complex text model)\ntext_embedding = tf.keras.layers.Embedding(input_dim=len(word_index) + 1, output_dim=128)(text_input)\ntext_embedding = tf.keras.layers.Flatten()(text_embedding)\n\n# Define image embedding layer using a larger model like InceptionV3\nimage_embedding = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\", input_shape=(299, 299, 3))(image_input)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:26:22.492516Z","iopub.execute_input":"2023-11-18T18:26:22.492914Z","iopub.status.idle":"2023-11-18T18:26:26.661156Z","shell.execute_reply.started":"2023-11-18T18:26:22.492882Z","shell.execute_reply":"2023-11-18T18:26:26.660365Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"  7%|▋         | 301/4278 [27:53<6:08:37,  5.56s/it]\n 27%|██▋       | 946/3452 [16:10<42:51,  1.03s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Concatenate text and image embeddings\ncombined = tf.keras.layers.concatenate([text_embedding, image_embedding])\n\n\n# Add more layers as needed for your specific task\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(combined)\n\nmodel_3 = tf.keras.models.Model(inputs=[text_input, image_input], outputs=output)\n\n# Compile the model\nmodel_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:26:28.593231Z","iopub.execute_input":"2023-11-18T18:26:28.593955Z","iopub.status.idle":"2023-11-18T18:26:28.628191Z","shell.execute_reply.started":"2023-11-18T18:26:28.593918Z","shell.execute_reply":"2023-11-18T18:26:28.627395Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":" \nmodel_3.fit([train_text_data, train_image_data], np.asarray(train_labels), epochs=10, validation_data=([test_text_data,test_image_data],np.asarray(test_labels)))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:26:44.390828Z","iopub.execute_input":"2023-11-18T18:26:44.391904Z","iopub.status.idle":"2023-11-18T18:29:02.583132Z","shell.execute_reply.started":"2023-11-18T18:26:44.391858Z","shell.execute_reply":"2023-11-18T18:29:02.582161Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 1/10\n108/108 [==============================] - 28s 210ms/step - loss: 7.4609 - accuracy: 0.5623 - val_loss: 3.0742 - val_accuracy: 0.5109\nEpoch 2/10\n108/108 [==============================] - 15s 133ms/step - loss: 3.1459 - accuracy: 0.5742 - val_loss: 2.9760 - val_accuracy: 0.4867\nEpoch 3/10\n108/108 [==============================] - 12s 114ms/step - loss: 4.6574 - accuracy: 0.5823 - val_loss: 3.1241 - val_accuracy: 0.6211\nEpoch 4/10\n108/108 [==============================] - 12s 112ms/step - loss: 2.2847 - accuracy: 0.6544 - val_loss: 4.7054 - val_accuracy: 0.6320\nEpoch 5/10\n108/108 [==============================] - 12s 107ms/step - loss: 1.7524 - accuracy: 0.7222 - val_loss: 2.3416 - val_accuracy: 0.5569\nEpoch 6/10\n108/108 [==============================] - 12s 108ms/step - loss: 1.2928 - accuracy: 0.7764 - val_loss: 3.4099 - val_accuracy: 0.4952\nEpoch 7/10\n108/108 [==============================] - 12s 112ms/step - loss: 1.4686 - accuracy: 0.7729 - val_loss: 2.0566 - val_accuracy: 0.6562\nEpoch 8/10\n108/108 [==============================] - 12s 110ms/step - loss: 0.8880 - accuracy: 0.8482 - val_loss: 2.0812 - val_accuracy: 0.6671\nEpoch 9/10\n108/108 [==============================] - 12s 111ms/step - loss: 0.4952 - accuracy: 0.8922 - val_loss: 3.1250 - val_accuracy: 0.6659\nEpoch 10/10\n108/108 [==============================] - 12s 108ms/step - loss: 0.3703 - accuracy: 0.9183 - val_loss: 2.2843 - val_accuracy: 0.6489\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f0e4436a800>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\npredictions = model_3.predict([test_text_data, test_image_data])\npredictions_labels = []\nfor i in predictions:\n    if i >= 0.5:\n        predictions_labels.append(1)\n    else:\n        predictions_labels.append(0)\n\n# Compute the AUROC\nauroc = roc_auc_score(test_labels, predictions_labels)\n\nprint(f'AUROC: {auroc}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:29:05.063400Z","iopub.execute_input":"2023-11-18T18:29:05.064093Z","iopub.status.idle":"2023-11-18T18:29:07.842340Z","shell.execute_reply.started":"2023-11-18T18:29:05.064051Z","shell.execute_reply":"2023-11-18T18:29:07.841371Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"26/26 [==============================] - 3s 84ms/step\nAUROC: 0.6122171945701358\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Compute confusion matrix\ncm = confusion_matrix(test_labels, predictions_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_labels, predictions_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:29:09.737756Z","iopub.execute_input":"2023-11-18T18:29:09.738402Z","iopub.status.idle":"2023-11-18T18:29:09.919366Z","shell.execute_reply.started":"2023-11-18T18:29:09.738368Z","shell.execute_reply":"2023-11-18T18:29:09.918431Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.71      0.75      0.73       520\n           1       0.53      0.47      0.50       306\n\n    accuracy                           0.65       826\n   macro avg       0.62      0.61      0.61       826\nweighted avg       0.64      0.65      0.64       826\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Third approach","metadata":{}},{"cell_type":"code","source":"# Import the necessary libraries\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.models import Model\nimport numpy as np\n\n# Load the ResNet model without the top classification layer\nbase_model = ResNet50(weights='imagenet', include_top=False)\n\n# # Define the layer from which you want to extract features\n# feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('desired_layer_name').output)\n\n# # Load and preprocess your image\n# img_path = 'your_image.jpg'\n# img = image.load_img(img_path, target_size=(224, 224))\n# x = image.img_to_array(img)\n# x = np.expand_dims(x, axis=0)\n# x = preprocess_input(x)\n\n# # Extract features from the image\n# features = feature_extractor.predict(x)\n\n# Now, 'features' contains the extracted features from your image using ResNet\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:30:31.104540Z","iopub.execute_input":"2023-11-18T18:30:31.105420Z","iopub.status.idle":"2023-11-18T18:30:33.544818Z","shell.execute_reply.started":"2023-11-18T18:30:31.105381Z","shell.execute_reply":"2023-11-18T18:30:33.543931Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-18T18:30:34.929421Z","iopub.execute_input":"2023-11-18T18:30:34.930140Z","iopub.status.idle":"2023-11-18T18:30:35.395066Z","shell.execute_reply.started":"2023-11-18T18:30:34.930104Z","shell.execute_reply":"2023-11-18T18:30:35.394069Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Model: \"resnet50\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_8 (InputLayer)           [(None, None, None,  0           []                               \n                                 3)]                                                              \n                                                                                                  \n conv1_pad (ZeroPadding2D)      (None, None, None,   0           ['input_8[0][0]']                \n                                3)                                                                \n                                                                                                  \n conv1_conv (Conv2D)            (None, None, None,   9472        ['conv1_pad[0][0]']              \n                                64)                                                               \n                                                                                                  \n conv1_bn (BatchNormalization)  (None, None, None,   256         ['conv1_conv[0][0]']             \n                                64)                                                               \n                                                                                                  \n conv1_relu (Activation)        (None, None, None,   0           ['conv1_bn[0][0]']               \n                                64)                                                               \n                                                                                                  \n pool1_pad (ZeroPadding2D)      (None, None, None,   0           ['conv1_relu[0][0]']             \n                                64)                                                               \n                                                                                                  \n pool1_pool (MaxPooling2D)      (None, None, None,   0           ['pool1_pad[0][0]']              \n                                64)                                                               \n                                                                                                  \n conv2_block1_1_conv (Conv2D)   (None, None, None,   4160        ['pool1_pool[0][0]']             \n                                64)                                                               \n                                                                                                  \n conv2_block1_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_1_conv[0][0]']    \n ization)                       64)                                                               \n                                                                                                  \n conv2_block1_1_relu (Activatio  (None, None, None,   0          ['conv2_block1_1_bn[0][0]']      \n n)                             64)                                                               \n                                                                                                  \n conv2_block1_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block1_1_relu[0][0]']    \n                                64)                                                               \n                                                                                                  \n conv2_block1_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_2_conv[0][0]']    \n ization)                       64)                                                               \n                                                                                                  \n conv2_block1_2_relu (Activatio  (None, None, None,   0          ['conv2_block1_2_bn[0][0]']      \n n)                             64)                                                               \n                                                                                                  \n conv2_block1_0_conv (Conv2D)   (None, None, None,   16640       ['pool1_pool[0][0]']             \n                                256)                                                              \n                                                                                                  \n conv2_block1_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_2_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv2_block1_0_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_0_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv2_block1_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_3_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv2_block1_add (Add)         (None, None, None,   0           ['conv2_block1_0_bn[0][0]',      \n                                256)                              'conv2_block1_3_bn[0][0]']      \n                                                                                                  \n conv2_block1_out (Activation)  (None, None, None,   0           ['conv2_block1_add[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv2_block2_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block1_out[0][0]']       \n                                64)                                                               \n                                                                                                  \n conv2_block2_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_1_conv[0][0]']    \n ization)                       64)                                                               \n                                                                                                  \n conv2_block2_1_relu (Activatio  (None, None, None,   0          ['conv2_block2_1_bn[0][0]']      \n n)                             64)                                                               \n                                                                                                  \n conv2_block2_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block2_1_relu[0][0]']    \n                                64)                                                               \n                                                                                                  \n conv2_block2_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_2_conv[0][0]']    \n ization)                       64)                                                               \n                                                                                                  \n conv2_block2_2_relu (Activatio  (None, None, None,   0          ['conv2_block2_2_bn[0][0]']      \n n)                             64)                                                               \n                                                                                                  \n conv2_block2_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block2_2_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv2_block2_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block2_3_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv2_block2_add (Add)         (None, None, None,   0           ['conv2_block1_out[0][0]',       \n                                256)                              'conv2_block2_3_bn[0][0]']      \n                                                                                                  \n conv2_block2_out (Activation)  (None, None, None,   0           ['conv2_block2_add[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv2_block3_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block2_out[0][0]']       \n                                64)                                                               \n                                                                                                  \n conv2_block3_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_1_conv[0][0]']    \n ization)                       64)                                                               \n                                                                                                  \n conv2_block3_1_relu (Activatio  (None, None, None,   0          ['conv2_block3_1_bn[0][0]']      \n n)                             64)                                                               \n                                                                                                  \n conv2_block3_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block3_1_relu[0][0]']    \n                                64)                                                               \n                                                                                                  \n conv2_block3_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_2_conv[0][0]']    \n ization)                       64)                                                               \n                                                                                                  \n conv2_block3_2_relu (Activatio  (None, None, None,   0          ['conv2_block3_2_bn[0][0]']      \n n)                             64)                                                               \n                                                                                                  \n conv2_block3_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block3_2_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv2_block3_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block3_3_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv2_block3_add (Add)         (None, None, None,   0           ['conv2_block2_out[0][0]',       \n                                256)                              'conv2_block3_3_bn[0][0]']      \n                                                                                                  \n conv2_block3_out (Activation)  (None, None, None,   0           ['conv2_block3_add[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv3_block1_1_conv (Conv2D)   (None, None, None,   32896       ['conv2_block3_out[0][0]']       \n                                128)                                                              \n                                                                                                  \n conv3_block1_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_1_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block1_1_relu (Activatio  (None, None, None,   0          ['conv3_block1_1_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block1_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block1_1_relu[0][0]']    \n                                128)                                                              \n                                                                                                  \n conv3_block1_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_2_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block1_2_relu (Activatio  (None, None, None,   0          ['conv3_block1_2_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block1_0_conv (Conv2D)   (None, None, None,   131584      ['conv2_block3_out[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv3_block1_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block1_2_relu[0][0]']    \n                                512)                                                              \n                                                                                                  \n conv3_block1_0_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_0_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv3_block1_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_3_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv3_block1_add (Add)         (None, None, None,   0           ['conv3_block1_0_bn[0][0]',      \n                                512)                              'conv3_block1_3_bn[0][0]']      \n                                                                                                  \n conv3_block1_out (Activation)  (None, None, None,   0           ['conv3_block1_add[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv3_block2_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block1_out[0][0]']       \n                                128)                                                              \n                                                                                                  \n conv3_block2_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_1_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block2_1_relu (Activatio  (None, None, None,   0          ['conv3_block2_1_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block2_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block2_1_relu[0][0]']    \n                                128)                                                              \n                                                                                                  \n conv3_block2_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_2_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block2_2_relu (Activatio  (None, None, None,   0          ['conv3_block2_2_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block2_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block2_2_relu[0][0]']    \n                                512)                                                              \n                                                                                                  \n conv3_block2_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block2_3_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv3_block2_add (Add)         (None, None, None,   0           ['conv3_block1_out[0][0]',       \n                                512)                              'conv3_block2_3_bn[0][0]']      \n                                                                                                  \n conv3_block2_out (Activation)  (None, None, None,   0           ['conv3_block2_add[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv3_block3_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block2_out[0][0]']       \n                                128)                                                              \n                                                                                                  \n conv3_block3_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_1_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block3_1_relu (Activatio  (None, None, None,   0          ['conv3_block3_1_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block3_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block3_1_relu[0][0]']    \n                                128)                                                              \n                                                                                                  \n conv3_block3_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_2_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block3_2_relu (Activatio  (None, None, None,   0          ['conv3_block3_2_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block3_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block3_2_relu[0][0]']    \n                                512)                                                              \n                                                                                                  \n conv3_block3_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block3_3_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv3_block3_add (Add)         (None, None, None,   0           ['conv3_block2_out[0][0]',       \n                                512)                              'conv3_block3_3_bn[0][0]']      \n                                                                                                  \n conv3_block3_out (Activation)  (None, None, None,   0           ['conv3_block3_add[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv3_block4_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block3_out[0][0]']       \n                                128)                                                              \n                                                                                                  \n conv3_block4_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_1_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block4_1_relu (Activatio  (None, None, None,   0          ['conv3_block4_1_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block4_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block4_1_relu[0][0]']    \n                                128)                                                              \n                                                                                                  \n conv3_block4_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_2_conv[0][0]']    \n ization)                       128)                                                              \n                                                                                                  \n conv3_block4_2_relu (Activatio  (None, None, None,   0          ['conv3_block4_2_bn[0][0]']      \n n)                             128)                                                              \n                                                                                                  \n conv3_block4_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block4_2_relu[0][0]']    \n                                512)                                                              \n                                                                                                  \n conv3_block4_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block4_3_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv3_block4_add (Add)         (None, None, None,   0           ['conv3_block3_out[0][0]',       \n                                512)                              'conv3_block4_3_bn[0][0]']      \n                                                                                                  \n conv3_block4_out (Activation)  (None, None, None,   0           ['conv3_block4_add[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv4_block1_1_conv (Conv2D)   (None, None, None,   131328      ['conv3_block4_out[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv4_block1_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_1_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block1_1_relu (Activatio  (None, None, None,   0          ['conv4_block1_1_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block1_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block1_1_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv4_block1_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_2_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block1_2_relu (Activatio  (None, None, None,   0          ['conv4_block1_2_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block1_0_conv (Conv2D)   (None, None, None,   525312      ['conv3_block4_out[0][0]']       \n                                1024)                                                             \n                                                                                                  \n conv4_block1_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block1_2_relu[0][0]']    \n                                1024)                                                             \n                                                                                                  \n conv4_block1_0_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_0_conv[0][0]']    \n ization)                       1024)                                                             \n                                                                                                  \n conv4_block1_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_3_conv[0][0]']    \n ization)                       1024)                                                             \n                                                                                                  \n conv4_block1_add (Add)         (None, None, None,   0           ['conv4_block1_0_bn[0][0]',      \n                                1024)                             'conv4_block1_3_bn[0][0]']      \n                                                                                                  \n conv4_block1_out (Activation)  (None, None, None,   0           ['conv4_block1_add[0][0]']       \n                                1024)                                                             \n                                                                                                  \n conv4_block2_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block1_out[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv4_block2_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_1_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block2_1_relu (Activatio  (None, None, None,   0          ['conv4_block2_1_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block2_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block2_1_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv4_block2_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_2_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block2_2_relu (Activatio  (None, None, None,   0          ['conv4_block2_2_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block2_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block2_2_relu[0][0]']    \n                                1024)                                                             \n                                                                                                  \n conv4_block2_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block2_3_conv[0][0]']    \n ization)                       1024)                                                             \n                                                                                                  \n conv4_block2_add (Add)         (None, None, None,   0           ['conv4_block1_out[0][0]',       \n                                1024)                             'conv4_block2_3_bn[0][0]']      \n                                                                                                  \n conv4_block2_out (Activation)  (None, None, None,   0           ['conv4_block2_add[0][0]']       \n                                1024)                                                             \n                                                                                                  \n conv4_block3_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block2_out[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv4_block3_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_1_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block3_1_relu (Activatio  (None, None, None,   0          ['conv4_block3_1_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block3_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block3_1_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv4_block3_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_2_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block3_2_relu (Activatio  (None, None, None,   0          ['conv4_block3_2_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block3_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block3_2_relu[0][0]']    \n                                1024)                                                             \n                                                                                                  \n conv4_block3_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block3_3_conv[0][0]']    \n ization)                       1024)                                                             \n                                                                                                  \n conv4_block3_add (Add)         (None, None, None,   0           ['conv4_block2_out[0][0]',       \n                                1024)                             'conv4_block3_3_bn[0][0]']      \n                                                                                                  \n conv4_block3_out (Activation)  (None, None, None,   0           ['conv4_block3_add[0][0]']       \n                                1024)                                                             \n                                                                                                  \n conv4_block4_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block3_out[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv4_block4_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_1_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block4_1_relu (Activatio  (None, None, None,   0          ['conv4_block4_1_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block4_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block4_1_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv4_block4_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_2_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block4_2_relu (Activatio  (None, None, None,   0          ['conv4_block4_2_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block4_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block4_2_relu[0][0]']    \n                                1024)                                                             \n                                                                                                  \n conv4_block4_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block4_3_conv[0][0]']    \n ization)                       1024)                                                             \n                                                                                                  \n conv4_block4_add (Add)         (None, None, None,   0           ['conv4_block3_out[0][0]',       \n                                1024)                             'conv4_block4_3_bn[0][0]']      \n                                                                                                  \n conv4_block4_out (Activation)  (None, None, None,   0           ['conv4_block4_add[0][0]']       \n                                1024)                                                             \n                                                                                                  \n conv4_block5_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block4_out[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv4_block5_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_1_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block5_1_relu (Activatio  (None, None, None,   0          ['conv4_block5_1_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block5_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block5_1_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv4_block5_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_2_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block5_2_relu (Activatio  (None, None, None,   0          ['conv4_block5_2_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block5_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block5_2_relu[0][0]']    \n                                1024)                                                             \n                                                                                                  \n conv4_block5_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block5_3_conv[0][0]']    \n ization)                       1024)                                                             \n                                                                                                  \n conv4_block5_add (Add)         (None, None, None,   0           ['conv4_block4_out[0][0]',       \n                                1024)                             'conv4_block5_3_bn[0][0]']      \n                                                                                                  \n conv4_block5_out (Activation)  (None, None, None,   0           ['conv4_block5_add[0][0]']       \n                                1024)                                                             \n                                                                                                  \n conv4_block6_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block5_out[0][0]']       \n                                256)                                                              \n                                                                                                  \n conv4_block6_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_1_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block6_1_relu (Activatio  (None, None, None,   0          ['conv4_block6_1_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block6_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block6_1_relu[0][0]']    \n                                256)                                                              \n                                                                                                  \n conv4_block6_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_2_conv[0][0]']    \n ization)                       256)                                                              \n                                                                                                  \n conv4_block6_2_relu (Activatio  (None, None, None,   0          ['conv4_block6_2_bn[0][0]']      \n n)                             256)                                                              \n                                                                                                  \n conv4_block6_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block6_2_relu[0][0]']    \n                                1024)                                                             \n                                                                                                  \n conv4_block6_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block6_3_conv[0][0]']    \n ization)                       1024)                                                             \n                                                                                                  \n conv4_block6_add (Add)         (None, None, None,   0           ['conv4_block5_out[0][0]',       \n                                1024)                             'conv4_block6_3_bn[0][0]']      \n                                                                                                  \n conv4_block6_out (Activation)  (None, None, None,   0           ['conv4_block6_add[0][0]']       \n                                1024)                                                             \n                                                                                                  \n conv5_block1_1_conv (Conv2D)   (None, None, None,   524800      ['conv4_block6_out[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv5_block1_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_1_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv5_block1_1_relu (Activatio  (None, None, None,   0          ['conv5_block1_1_bn[0][0]']      \n n)                             512)                                                              \n                                                                                                  \n conv5_block1_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block1_1_relu[0][0]']    \n                                512)                                                              \n                                                                                                  \n conv5_block1_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_2_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv5_block1_2_relu (Activatio  (None, None, None,   0          ['conv5_block1_2_bn[0][0]']      \n n)                             512)                                                              \n                                                                                                  \n conv5_block1_0_conv (Conv2D)   (None, None, None,   2099200     ['conv4_block6_out[0][0]']       \n                                2048)                                                             \n                                                                                                  \n conv5_block1_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block1_2_relu[0][0]']    \n                                2048)                                                             \n                                                                                                  \n conv5_block1_0_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_0_conv[0][0]']    \n ization)                       2048)                                                             \n                                                                                                  \n conv5_block1_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_3_conv[0][0]']    \n ization)                       2048)                                                             \n                                                                                                  \n conv5_block1_add (Add)         (None, None, None,   0           ['conv5_block1_0_bn[0][0]',      \n                                2048)                             'conv5_block1_3_bn[0][0]']      \n                                                                                                  \n conv5_block1_out (Activation)  (None, None, None,   0           ['conv5_block1_add[0][0]']       \n                                2048)                                                             \n                                                                                                  \n conv5_block2_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block1_out[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv5_block2_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_1_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv5_block2_1_relu (Activatio  (None, None, None,   0          ['conv5_block2_1_bn[0][0]']      \n n)                             512)                                                              \n                                                                                                  \n conv5_block2_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block2_1_relu[0][0]']    \n                                512)                                                              \n                                                                                                  \n conv5_block2_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_2_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv5_block2_2_relu (Activatio  (None, None, None,   0          ['conv5_block2_2_bn[0][0]']      \n n)                             512)                                                              \n                                                                                                  \n conv5_block2_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block2_2_relu[0][0]']    \n                                2048)                                                             \n                                                                                                  \n conv5_block2_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block2_3_conv[0][0]']    \n ization)                       2048)                                                             \n                                                                                                  \n conv5_block2_add (Add)         (None, None, None,   0           ['conv5_block1_out[0][0]',       \n                                2048)                             'conv5_block2_3_bn[0][0]']      \n                                                                                                  \n conv5_block2_out (Activation)  (None, None, None,   0           ['conv5_block2_add[0][0]']       \n                                2048)                                                             \n                                                                                                  \n conv5_block3_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block2_out[0][0]']       \n                                512)                                                              \n                                                                                                  \n conv5_block3_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_1_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv5_block3_1_relu (Activatio  (None, None, None,   0          ['conv5_block3_1_bn[0][0]']      \n n)                             512)                                                              \n                                                                                                  \n conv5_block3_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block3_1_relu[0][0]']    \n                                512)                                                              \n                                                                                                  \n conv5_block3_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_2_conv[0][0]']    \n ization)                       512)                                                              \n                                                                                                  \n conv5_block3_2_relu (Activatio  (None, None, None,   0          ['conv5_block3_2_bn[0][0]']      \n n)                             512)                                                              \n                                                                                                  \n conv5_block3_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block3_2_relu[0][0]']    \n                                2048)                                                             \n                                                                                                  \n conv5_block3_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block3_3_conv[0][0]']    \n ization)                       2048)                                                             \n                                                                                                  \n conv5_block3_add (Add)         (None, None, None,   0           ['conv5_block2_out[0][0]',       \n                                2048)                             'conv5_block3_3_bn[0][0]']      \n                                                                                                  \n conv5_block3_out (Activation)  (None, None, None,   0           ['conv5_block3_add[0][0]']       \n                                2048)                                                             \n                                                                                                  \n==================================================================================================\nTotal params: 23,587,712\nTrainable params: 23,534,592\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"last_layer_output = base_model.layers[-1].output","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:30:43.033383Z","iopub.execute_input":"2023-11-18T18:30:43.034255Z","iopub.status.idle":"2023-11-18T18:30:43.038833Z","shell.execute_reply.started":"2023-11-18T18:30:43.034221Z","shell.execute_reply":"2023-11-18T18:30:43.037832Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"reshaped_output = tf.keras.layers.Reshape(target_shape=(100352,))(last_layer_output)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:30:45.798049Z","iopub.execute_input":"2023-11-18T18:30:45.798897Z","iopub.status.idle":"2023-11-18T18:30:45.812032Z","shell.execute_reply.started":"2023-11-18T18:30:45.798860Z","shell.execute_reply":"2023-11-18T18:30:45.810905Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Define the layer from which you want to extract features\nfeature_extractor = Model(inputs=base_model.input, outputs=reshaped_output)\ntrain_preprocessed_resnet_50 = []\ntest_preprocessed_resnet_50 = []\nfor i in tqdm(train_image_data_paths):\n    img = image.load_img(DATA_PATH+f'''/{i}''', target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    x = preprocess_input(x)\n\n    train_preprocessed_resnet_50.append(x)\n\nfor i in tqdm(test_image_data_paths):\n    img = image.load_img(DATA_PATH+f'''/{i}''', target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    x = preprocess_input(x)\n\n    test_preprocessed_resnet_50.append(x)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:31:47.881583Z","iopub.execute_input":"2023-11-18T18:31:47.881994Z","iopub.status.idle":"2023-11-18T18:32:48.061254Z","shell.execute_reply.started":"2023-11-18T18:31:47.881963Z","shell.execute_reply":"2023-11-18T18:32:48.060362Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"100%|██████████| 3452/3452 [00:48<00:00, 71.26it/s]\n100%|██████████| 826/826 [00:11<00:00, 70.59it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"text_embedding","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:30:58.799935Z","iopub.execute_input":"2023-11-18T18:30:58.800316Z","iopub.status.idle":"2023-11-18T18:30:58.806491Z","shell.execute_reply.started":"2023-11-18T18:30:58.800272Z","shell.execute_reply":"2023-11-18T18:30:58.805428Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 12800) dtype=float32 (created by layer 'flatten_2')>"},"metadata":{}}]},{"cell_type":"code","source":"feature_extractor.output","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:32:52.800857Z","iopub.execute_input":"2023-11-18T18:32:52.801222Z","iopub.status.idle":"2023-11-18T18:32:52.807435Z","shell.execute_reply.started":"2023-11-18T18:32:52.801192Z","shell.execute_reply":"2023-11-18T18:32:52.806470Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 100352) dtype=float32 (created by layer 'reshape')>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Concatenate text and image embeddings\ncombined = tf.keras.layers.concatenate([text_embedding, feature_extractor.output])\n\n\n# Add more layers as needed for your specific task\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(combined)\n\nmodel_4 = tf.keras.models.Model(inputs=[text_input, base_model.input], outputs=output)\n\n# Compile the model\nmodel_4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:32:54.263462Z","iopub.execute_input":"2023-11-18T18:32:54.264223Z","iopub.status.idle":"2023-11-18T18:32:54.316924Z","shell.execute_reply.started":"2023-11-18T18:32:54.264186Z","shell.execute_reply":"2023-11-18T18:32:54.316144Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"train_preprocessed_resnet_50 = np.reshape(np.asarray(train_preprocessed_resnet_50), (len(train_preprocessed_resnet_50), 224, 224, 3))\ntest_preprocessed_resnet_50 = np.reshape(np.asarray(test_preprocessed_resnet_50), (len(test_preprocessed_resnet_50), 224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:33:21.851507Z","iopub.execute_input":"2023-11-18T18:33:21.851909Z","iopub.status.idle":"2023-11-18T18:33:25.035580Z","shell.execute_reply.started":"2023-11-18T18:33:21.851878Z","shell.execute_reply":"2023-11-18T18:33:25.034460Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"tf.config.experimental_run_functions_eagerly(True)\nmodel_4.fit([train_text_data, train_preprocessed_resnet_50], np.asarray(train_labels), epochs=10,\n         validation_data=([test_text_data,test_preprocessed_resnet_50 ], np.asarray(test_labels)))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:33:28.921836Z","iopub.execute_input":"2023-11-18T18:33:28.922549Z","iopub.status.idle":"2023-11-18T18:50:49.571993Z","shell.execute_reply.started":"2023-11-18T18:33:28.922511Z","shell.execute_reply":"2023-11-18T18:50:49.571048Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n108/108 [==============================] - 110s 978ms/step - loss: 1.8694 - accuracy: 0.7451 - val_loss: 3720.4268 - val_accuracy: 0.6283\nEpoch 2/10\n108/108 [==============================] - 102s 948ms/step - loss: 0.9531 - accuracy: 0.8830 - val_loss: 224.4380 - val_accuracy: 0.6283\nEpoch 3/10\n108/108 [==============================] - 103s 952ms/step - loss: 0.5840 - accuracy: 0.9041 - val_loss: 15.5284 - val_accuracy: 0.5944\nEpoch 4/10\n108/108 [==============================] - 103s 951ms/step - loss: 0.4170 - accuracy: 0.9177 - val_loss: 67.6055 - val_accuracy: 0.5605\nEpoch 5/10\n108/108 [==============================] - 103s 951ms/step - loss: 0.5098 - accuracy: 0.9224 - val_loss: 16.1855 - val_accuracy: 0.6598\nEpoch 6/10\n108/108 [==============================] - 103s 952ms/step - loss: 0.3786 - accuracy: 0.9302 - val_loss: 4.0610 - val_accuracy: 0.6332\nEpoch 7/10\n108/108 [==============================] - 103s 951ms/step - loss: 0.2350 - accuracy: 0.9360 - val_loss: 2.5053 - val_accuracy: 0.6743\nEpoch 8/10\n108/108 [==============================] - 104s 961ms/step - loss: 0.1930 - accuracy: 0.9444 - val_loss: 3.2018 - val_accuracy: 0.6538\nEpoch 9/10\n108/108 [==============================] - 103s 955ms/step - loss: 0.1105 - accuracy: 0.9557 - val_loss: 1.3738 - val_accuracy: 0.6768\nEpoch 10/10\n108/108 [==============================] - 103s 956ms/step - loss: 0.1327 - accuracy: 0.9508 - val_loss: 1.7437 - val_accuracy: 0.6525\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f0e0c6af070>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\npredictions = model_4.predict([test_text_data, test_image_data])\npredictions_labels = []\nfor i in predictions:\n    if i >= 0.5:\n        predictions_labels.append(1)\n    else:\n        predictions_labels.append(0)\n\n# Compute the AUROC\nauroc = roc_auc_score(test_labels, predictions_labels)\n\nprint(f'AUROC: {auroc}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:57:31.908279Z","iopub.execute_input":"2023-11-18T18:57:31.909250Z","iopub.status.idle":"2023-11-18T18:57:35.019179Z","shell.execute_reply.started":"2023-11-18T18:57:31.909215Z","shell.execute_reply":"2023-11-18T18:57:35.018157Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"26/26 [==============================] - 3s 116ms/step\nAUROC: 0.5419808949220714\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Compute confusion matrix\ncm = confusion_matrix(test_labels, predictions_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_labels, predictions_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:58:03.002320Z","iopub.execute_input":"2023-11-18T18:58:03.003238Z","iopub.status.idle":"2023-11-18T18:58:03.190382Z","shell.execute_reply.started":"2023-11-18T18:58:03.003190Z","shell.execute_reply":"2023-11-18T18:58:03.189404Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.65      0.88      0.75       520\n           1       0.50      0.20      0.29       306\n\n    accuracy                           0.63       826\n   macro avg       0.58      0.54      0.52       826\nweighted avg       0.60      0.63      0.58       826\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom transformers import AutoProcessor, TFCLIPVisionModel\n\nmodel = TFCLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\n\ninputs = processor(images=image, return_tensors=\"tf\")\n\noutputs = model(**inputs)\nlast_hidden_state = outputs.last_hidden_state\npooled_output = outputs.pooler_output  # pooled CLS states","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:47:08.684251Z","iopub.execute_input":"2023-11-18T19:47:08.685021Z","iopub.status.idle":"2023-11-18T19:47:11.777792Z","shell.execute_reply.started":"2023-11-18T19:47:08.684987Z","shell.execute_reply":"2023-11-18T19:47:11.776921Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing TFCLIPVisionModel: ['clip/text_model/embeddings/token_embedding/weight:0', 'clip/text_model/encoder/layers_._8/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._5/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._11/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._8/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._3/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._10/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._1/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._9/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._9/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._4/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._6/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._4/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._5/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._4/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._9/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._6/self_attn/v_proj/bias:0', 'clip/text_model/final_layer_norm/gamma:0', 'clip/text_model/encoder/layers_._4/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._0/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._0/self_attn/k_proj/bias:0', 'clip/logit_scale:0', 'clip/text_model/encoder/layers_._7/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._10/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._7/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._9/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._9/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._4/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._11/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._5/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._1/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._4/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._3/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._5/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._7/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._1/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._9/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._7/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._7/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._1/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._2/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._11/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._1/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._0/self_attn/k_proj/kernel:0', 'clip/text_projection/kernel:0', 'clip/text_model/encoder/layers_._3/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._8/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._9/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._3/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._7/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._10/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._0/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._6/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._2/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._6/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._11/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._10/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._6/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._11/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._9/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._4/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._4/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._8/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._8/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._9/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._5/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._3/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._8/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._7/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._2/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._6/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._3/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._0/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._9/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._8/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._5/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._2/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._7/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._8/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._2/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._6/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._4/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._2/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._4/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._7/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._5/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._2/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._6/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._10/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._2/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._0/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._3/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._5/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._6/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._10/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._1/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._1/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._2/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._7/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._3/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._10/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._4/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._5/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._8/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._0/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._8/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._11/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._2/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._5/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._8/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._5/mlp/fc1/kernel:0', 'clip/text_model/final_layer_norm/beta:0', 'clip/text_model/encoder/layers_._6/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._10/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._0/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._10/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._11/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._2/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._4/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._2/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._2/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._3/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._9/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._5/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._1/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._10/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._10/self_attn/k_proj/kernel:0', 'clip/text_model/encoder/layers_._5/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._2/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._6/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._7/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._1/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._5/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._11/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._6/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._10/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._3/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._3/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._11/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._2/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._0/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._0/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._1/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._0/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._10/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._11/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._4/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._1/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._3/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._5/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._11/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._7/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._0/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._1/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._11/mlp/fc2/kernel:0', 'clip/text_model/embeddings/position_embedding/embeddings:0', 'clip/text_model/encoder/layers_._0/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._10/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._1/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._7/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._9/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._10/self_attn/k_proj/bias:0', 'clip/text_model/encoder/layers_._6/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._9/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._5/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._6/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._6/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._8/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._7/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._9/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._9/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._3/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._8/layer_norm1/beta:0', 'clip/text_model/encoder/layers_._1/layer_norm2/gamma:0', 'clip/text_model/encoder/layers_._7/layer_norm1/gamma:0', 'clip/text_model/encoder/layers_._1/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._4/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._8/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._11/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._3/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._0/self_attn/v_proj/kernel:0', 'clip/visual_projection/kernel:0', 'clip/text_model/encoder/layers_._8/mlp/fc2/kernel:0', 'clip/text_model/encoder/layers_._3/self_attn/out_proj/kernel:0', 'clip/text_model/encoder/layers_._0/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._8/mlp/fc2/bias:0', 'clip/text_model/encoder/layers_._4/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._0/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._6/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._10/self_attn/q_proj/kernel:0', 'clip/text_model/encoder/layers_._1/self_attn/v_proj/kernel:0', 'clip/text_model/encoder/layers_._11/mlp/fc1/bias:0', 'clip/text_model/encoder/layers_._4/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._2/self_attn/q_proj/bias:0', 'clip/text_model/encoder/layers_._7/self_attn/v_proj/bias:0', 'clip/text_model/encoder/layers_._9/layer_norm2/beta:0', 'clip/text_model/encoder/layers_._11/mlp/fc1/kernel:0', 'clip/text_model/encoder/layers_._3/self_attn/out_proj/bias:0', 'clip/text_model/encoder/layers_._11/mlp/fc2/bias:0']\n- This IS expected if you are initializing TFCLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFCLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFCLIPVisionModel were initialized from the model checkpoint at openai/clip-vit-base-patch32.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFCLIPVisionModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFCLIPTextModel\n\nmodel = TFCLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\ntokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n\ninputs = tokenizer([\"a photo of a cat\"], padding=True, return_tensors=\"tf\")\n\noutputs = model(**inputs)\nlast_hidden_state = outputs.last_hidden_state\npooled_output = outputs.pooler_output  # pooled (EOS token) states\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:47:18.288159Z","iopub.execute_input":"2023-11-18T19:47:18.288954Z","iopub.status.idle":"2023-11-18T19:47:20.024689Z","shell.execute_reply.started":"2023-11-18T19:47:18.288919Z","shell.execute_reply":"2023-11-18T19:47:20.023883Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing TFCLIPTextModel: ['clip/vision_model/encoder/layers_._7/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._9/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._1/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._4/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._0/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._7/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._8/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._1/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._9/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._7/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._4/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._10/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._7/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._5/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._10/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._5/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._4/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._10/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._0/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._5/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._5/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._1/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._6/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._4/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._9/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._9/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._4/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._5/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._0/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._1/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._0/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._9/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._10/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._3/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._2/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._5/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._11/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._8/self_attn/q_proj/kernel:0', 'clip/logit_scale:0', 'clip/vision_model/pre_layrnorm/gamma:0', 'clip/vision_model/encoder/layers_._3/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._6/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._0/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._6/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._8/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._4/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._11/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._7/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._10/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._1/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._8/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._8/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._2/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._9/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._11/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._5/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._5/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._6/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._11/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._11/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._0/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._4/self_attn/v_proj/bias:0', 'clip/vision_model/embeddings/class_embedding:0', 'clip/text_projection/kernel:0', 'clip/vision_model/encoder/layers_._4/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._5/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._9/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._11/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._1/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._4/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._2/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._8/self_attn/out_proj/bias:0', 'clip/vision_model/post_layernorm/beta:0', 'clip/vision_model/encoder/layers_._5/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._2/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._3/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._5/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._11/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._9/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._9/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._11/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._5/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._4/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._6/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._10/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._1/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._3/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._7/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._6/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._2/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._11/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._10/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._4/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._10/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._7/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._6/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._0/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._8/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._3/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._0/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._8/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._6/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._2/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._2/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._0/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._2/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._7/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._6/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._7/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._11/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._1/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._1/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._3/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._6/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._8/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._4/mlp/fc2/kernel:0', 'clip/vision_model/embeddings/patch_embedding/kernel:0', 'clip/vision_model/encoder/layers_._8/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._9/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._7/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._4/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._2/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._9/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._8/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._7/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._3/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._8/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._11/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._3/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._11/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._9/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._10/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._7/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._0/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._7/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._2/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._0/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._2/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._3/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._11/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._7/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._10/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._9/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._11/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._10/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._9/mlp/fc1/kernel:0', 'clip/vision_model/pre_layrnorm/beta:0', 'clip/vision_model/encoder/layers_._1/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._3/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._6/self_attn/v_proj/bias:0', 'clip/vision_model/embeddings/position_embedding/embeddings:0', 'clip/vision_model/encoder/layers_._6/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._3/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._0/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._8/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._5/layer_norm2/gamma:0', 'clip/vision_model/post_layernorm/gamma:0', 'clip/vision_model/encoder/layers_._1/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._1/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._6/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._4/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._2/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._5/self_attn/out_proj/kernel:0', 'clip/vision_model/encoder/layers_._10/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._2/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._6/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._10/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._1/layer_norm2/gamma:0', 'clip/vision_model/encoder/layers_._4/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._0/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._9/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._2/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._8/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._0/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._2/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._8/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._5/self_attn/q_proj/kernel:0', 'clip/vision_model/encoder/layers_._3/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._3/mlp/fc1/kernel:0', 'clip/vision_model/encoder/layers_._3/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._10/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._6/layer_norm1/gamma:0', 'clip/vision_model/encoder/layers_._3/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._3/mlp/fc2/bias:0', 'clip/vision_model/encoder/layers_._1/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._11/layer_norm1/beta:0', 'clip/vision_model/encoder/layers_._0/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._7/self_attn/q_proj/bias:0', 'clip/visual_projection/kernel:0', 'clip/vision_model/encoder/layers_._9/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._1/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._1/mlp/fc1/bias:0', 'clip/vision_model/encoder/layers_._4/self_attn/q_proj/bias:0', 'clip/vision_model/encoder/layers_._11/self_attn/v_proj/bias:0', 'clip/vision_model/encoder/layers_._6/layer_norm2/beta:0', 'clip/vision_model/encoder/layers_._0/self_attn/k_proj/bias:0', 'clip/vision_model/encoder/layers_._10/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._5/self_attn/out_proj/bias:0', 'clip/vision_model/encoder/layers_._10/self_attn/v_proj/kernel:0', 'clip/vision_model/encoder/layers_._8/mlp/fc2/kernel:0', 'clip/vision_model/encoder/layers_._7/self_attn/k_proj/kernel:0', 'clip/vision_model/encoder/layers_._2/self_attn/out_proj/bias:0']\n- This IS expected if you are initializing TFCLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFCLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFCLIPTextModel were initialized from the model checkpoint at openai/clip-vit-base-patch32.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFCLIPTextModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, Concatenate\nfrom transformers import TFCLIPVisionModel, TFCLIPTextModel\nimport tensorflow as tf\ntext_shape = (128,) \nvision_inputs = Input(shape=(3, 224, 224), name='vision_inputs')\n# Assuming your text data is in a variable called text_data\ntokenized_text = tokenizer(list(data['text'].values), padding=True, truncation=True, return_tensors=\"tf\")\n\n# Now, text_inputs can be constructed using tokenized_text['input_ids']\ntext_inputs = Input(shape=(tokenized_text['input_ids'].shape[1],), dtype=tf.int32, name='text_inputs')\n\n# Assume that vision_model and text_model are your pre-trained CLIP vision and text models\nvision_model = TFCLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\ntext_model = TFCLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n# Get the pooled outputs\nvision_pooled_output = vision_model(vision_inputs)['pooler_output']\ntext_pooled_output = text_model(text_inputs)['pooler_output']\n\n# Concatenate the pooled outputs\nconcatenated = Concatenate()([vision_pooled_output, text_pooled_output])\n\n# Pass the concatenated output to a Dense layer with a single unit and a sigmoid activation function\noutput = Dense(1, activation='sigmoid')(concatenated)\n\n# Create a Keras model\nmodel = Model(inputs=[vision_inputs, text_inputs], outputs=output)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv(\"/kaggle/input/dm-dataset/data mining project/hatefulmemes.csv\")\ndata.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:54:31.341513Z","iopub.execute_input":"2023-11-18T19:54:31.341897Z","iopub.status.idle":"2023-11-18T19:54:31.412507Z","shell.execute_reply.started":"2023-11-18T19:54:31.341865Z","shell.execute_reply":"2023-11-18T19:54:31.411529Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"      id            img  label  \\\n0  42953  img/42953.png      0   \n1  23058  img/23058.png      0   \n2  13894  img/13894.png      0   \n3  37408  img/37408.png      0   \n4  82403  img/82403.png      0   \n\n                                                text  \n0   its their character not their color that matters  \n1  don't be afraid to love again everyone is not ...  \n2                           putting bows on your pet  \n3  i love everything and everybody! except for sq...  \n4  everybody loves chocolate chip cookies, even h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img</th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42953</td>\n      <td>img/42953.png</td>\n      <td>0</td>\n      <td>its their character not their color that matters</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23058</td>\n      <td>img/23058.png</td>\n      <td>0</td>\n      <td>don't be afraid to love again everyone is not ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13894</td>\n      <td>img/13894.png</td>\n      <td>0</td>\n      <td>putting bows on your pet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37408</td>\n      <td>img/37408.png</td>\n      <td>0</td>\n      <td>i love everything and everybody! except for sq...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82403</td>\n      <td>img/82403.png</td>\n      <td>0</td>\n      <td>everybody loves chocolate chip cookies, even h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:56:36.179778Z","iopub.execute_input":"2023-11-18T19:56:36.180125Z","iopub.status.idle":"2023-11-18T19:56:36.242704Z","shell.execute_reply.started":"2023-11-18T19:56:36.180100Z","shell.execute_reply":"2023-11-18T19:56:36.241797Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n vision_inputs (InputLayer)     [(None, 3, 224, 224  0           []                               \n                                )]                                                                \n                                                                                                  \n text_inputs (InputLayer)       [(None, 77)]         0           []                               \n                                                                                                  \n tfclip_vision_model_8 (TFCLIPV  TFBaseModelOutputWi  87456000   ['vision_inputs[0][0]']          \n isionModel)                    thPooling(last_hidd                                               \n                                en_state=(None, 50,                                               \n                                 768),                                                            \n                                 pooler_output=(Non                                               \n                                e, 768),                                                          \n                                 hidden_states=None                                               \n                                , attentions=None)                                                \n                                                                                                  \n tfclip_text_model_8 (TFCLIPTex  TFBaseModelOutputWi  63165952   ['text_inputs[0][0]']            \n tModel)                        thPooling(last_hidd                                               \n                                en_state=(None, 77,                                               \n                                 512),                                                            \n                                 pooler_output=(Non                                               \n                                e, 512),                                                          \n                                 hidden_states=None                                               \n                                , attentions=None)                                                \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 1280)         0           ['tfclip_vision_model_8[0][1]',  \n                                                                  'tfclip_text_model_8[0][1]']    \n                                                                                                  \n dense_1 (Dense)                (None, 1)            1281        ['concatenate_1[0][0]']          \n                                                                                                  \n==================================================================================================\nTotal params: 150,623,233\nTrainable params: 150,623,233\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_testv = train_test_split(data, shuffle=True, random_state=42, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:00:42.185668Z","iopub.execute_input":"2023-11-18T20:00:42.186062Z","iopub.status.idle":"2023-11-18T20:00:42.196185Z","shell.execute_reply.started":"2023-11-18T20:00:42.186033Z","shell.execute_reply":"2023-11-18T20:00:42.195110Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ntrain_image_data = []\ntrain_text_data = []\ntrain_labels = []\n\ntest_image_data = []\ntest_text_data = []\ntest_labels = []\nc = 1\nc1 = 1\nfor index, row in tqdm(X_train.iterrows(), total=len(X_train)):\n\n    try:\n        image_path = f\"/kaggle/input/dm-dataset/data mining project/{row['img']}\"\n        image = Image.open(image_path)\n        vision_inputs = processor(images=image, return_tensors=\"tf\")\n        text_inputs = tokenizer([row[\"text\"]], padding=True, return_tensors=\"tf\")\n        # Get the pooled outputs\n        vision_pooled_output = vision_model(vision_inputs)['pooler_output']\n        text_pooled_output = text_model(text_inputs)['pooler_output']\n        train_image_data.append(vision_pooled_output)\n        train_text_data.append(text_pooled_output)\n        train_labels.append(row['label'])\n    except Exception as e:\n        pass\n\n\nfor index, row in tqdm(X_testv.iterrows(), total=len(X_testv)):\n\n    try:\n        image_path = f\"/kaggle/input/dm-dataset/data mining project/{row['img']}\"\n        image = Image.open(image_path)\n        vision_inputs = processor(images=image, return_tensors=\"tf\")\n        text_inputs = tokenizer([row[\"text\"]], padding=True, return_tensors=\"tf\")\n        # Get the pooled outputs\n        vision_pooled_output = vision_model(vision_inputs)['pooler_output']\n        text_pooled_output = text_model(text_inputs)['pooler_output']\n        test_image_data.append(vision_pooled_output)\n        test_text_data.append(text_pooled_output)\n        test_labels.append(row['label'])\n    except Exception as e:\n        pass\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:14:33.978810Z","iopub.execute_input":"2023-11-18T20:14:33.979191Z","iopub.status.idle":"2023-11-18T20:44:52.139005Z","shell.execute_reply.started":"2023-11-18T20:14:33.979159Z","shell.execute_reply":"2023-11-18T20:44:52.137977Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"100%|██████████| 6800/6800 [24:26<00:00,  4.64it/s]\n100%|██████████| 1700/1700 [05:52<00:00,  4.83it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\ntrain_image_data = np.asarray(train_image_data)\ntrain_text_data = np.asarray(train_text_data)\ntrain_labels = np.asarray(train_labels)\n\ntest_image_data = np.asarray(test_image_data)\ntest_text_data = np.asarray(test_text_data)\ntest_labels = np.asarray(test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:55:44.932855Z","iopub.execute_input":"2023-11-18T20:55:44.933725Z","iopub.status.idle":"2023-11-18T20:55:45.261887Z","shell.execute_reply.started":"2023-11-18T20:55:44.933658Z","shell.execute_reply":"2023-11-18T20:55:45.261027Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"train_image_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:56:10.058190Z","iopub.execute_input":"2023-11-18T20:56:10.059118Z","iopub.status.idle":"2023-11-18T20:56:10.065023Z","shell.execute_reply.started":"2023-11-18T20:56:10.059081Z","shell.execute_reply":"2023-11-18T20:56:10.064114Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"(3452, 1, 768)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras import Model\nfrom tensorflow.keras.layers import Dense, Concatenate, Input\n\n# Assume that the size of your image and text embeddings is 512\nimage_embedding_size = 768\ntext_embedding_size = 512\n\n# Create input layers\nimage_input = Input(shape=(image_embedding_size,))\ntext_input = Input(shape=(text_embedding_size,))\n\n# Concatenate the inputs\nconcatenated = Concatenate()([image_input, text_input])\n\n# Add a Dense layer with a single unit and a sigmoid activation function\noutput = Dense(1, activation='sigmoid')(concatenated)\n\n# Create the model\nmodel = Model(inputs=[image_input, text_input], outputs=output)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:56:13.430117Z","iopub.execute_input":"2023-11-18T20:56:13.430851Z","iopub.status.idle":"2023-11-18T20:56:13.460286Z","shell.execute_reply.started":"2023-11-18T20:56:13.430818Z","shell.execute_reply":"2023-11-18T20:56:13.459426Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"train_image_data = np.squeeze(train_image_data, axis=1)\ntrain_text_data = np.squeeze(train_text_data, axis=1)\ntest_image_data = np.squeeze(test_image_data, axis=1)\ntest_text_data = np.squeeze(test_text_data, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:56:14.858468Z","iopub.execute_input":"2023-11-18T20:56:14.858997Z","iopub.status.idle":"2023-11-18T20:56:14.864177Z","shell.execute_reply.started":"2023-11-18T20:56:14.858961Z","shell.execute_reply":"2023-11-18T20:56:14.863263Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(\"train_image_data.pkl\", \"wb\") as f:\n    pickle.dump(train_image_data, f)\nwith open(\"test_image_data.pkl\", \"wb\") as f:\n    pickle.dump(test_image_data, f)\nwith open(\"train_text_data.pkl\", \"wb\") as f:\n    pickle.dump(train_text_data, f)\nwith open(\"test_text_data.pkl\", \"wb\") as f:\n    pickle.dump(test_text_data, f)\nwith open(\"train_labels.pkl\", \"wb\") as f:\n    pickle.dump(train_labels, f)\nwith open(\"test_labels.pkl\", \"wb\") as f:\n    pickle.dump(test_labels, f)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:56:17.186282Z","iopub.execute_input":"2023-11-18T20:56:17.187127Z","iopub.status.idle":"2023-11-18T20:56:17.217272Z","shell.execute_reply.started":"2023-11-18T20:56:17.187092Z","shell.execute_reply":"2023-11-18T20:56:17.216471Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:56:20.022435Z","iopub.execute_input":"2023-11-18T20:56:20.023302Z","iopub.status.idle":"2023-11-18T20:56:20.035006Z","shell.execute_reply.started":"2023-11-18T20:56:20.023263Z","shell.execute_reply":"2023-11-18T20:56:20.034062Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"model.fit([train_image_data,train_text_data], train_labels, epochs=10, validation_data=([test_image_data, test_text_data], test_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:56:23.618654Z","iopub.execute_input":"2023-11-18T20:56:23.619487Z","iopub.status.idle":"2023-11-18T20:56:28.400411Z","shell.execute_reply.started":"2023-11-18T20:56:23.619457Z","shell.execute_reply":"2023-11-18T20:56:28.399526Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"Epoch 1/10\n108/108 [==============================] - 1s 5ms/step - loss: 0.6485 - accuracy: 0.6622 - val_loss: 0.5873 - val_accuracy: 0.6998\nEpoch 2/10\n108/108 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7381 - val_loss: 0.5665 - val_accuracy: 0.7179\nEpoch 3/10\n108/108 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7674 - val_loss: 0.5545 - val_accuracy: 0.7228\nEpoch 4/10\n108/108 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7914 - val_loss: 0.5401 - val_accuracy: 0.7421\nEpoch 5/10\n108/108 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7975 - val_loss: 0.5282 - val_accuracy: 0.7349\nEpoch 6/10\n108/108 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8123 - val_loss: 0.5313 - val_accuracy: 0.7409\nEpoch 7/10\n108/108 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8218 - val_loss: 0.5315 - val_accuracy: 0.7349\nEpoch 8/10\n108/108 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8276 - val_loss: 0.5401 - val_accuracy: 0.7324\nEpoch 9/10\n108/108 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.8268 - val_loss: 0.5407 - val_accuracy: 0.7373\nEpoch 10/10\n108/108 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8305 - val_loss: 0.5486 - val_accuracy: 0.7337\n","output_type":"stream"},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7afa4d2569b0>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\npredictions = model.predict([test_image_data, test_text_data])\npredictions_labels = []\nfor i in predictions:\n    if i >= 0.5:\n        predictions_labels.append(1)\n    else:\n        predictions_labels.append(0)\n\n# Compute the AUROC\nauroc = roc_auc_score(test_labels, predictions_labels)\n\nprint(f'AUROC: {auroc}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:57:17.263090Z","iopub.execute_input":"2023-11-18T20:57:17.263454Z","iopub.status.idle":"2023-11-18T20:57:17.479001Z","shell.execute_reply.started":"2023-11-18T20:57:17.263423Z","shell.execute_reply":"2023-11-18T20:57:17.478004Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"26/26 [==============================] - 0s 1ms/step\nAUROC: 0.6889391654097536\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Compute confusion matrix\ncm = confusion_matrix(test_labels, predictions_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_labels, predictions_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:57:46.387301Z","iopub.execute_input":"2023-11-18T20:57:46.387684Z","iopub.status.idle":"2023-11-18T20:57:46.741348Z","shell.execute_reply.started":"2023-11-18T20:57:46.387655Z","shell.execute_reply":"2023-11-18T20:57:46.740281Z"},"trusted":true},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.75      0.86      0.80       520\n           1       0.69      0.52      0.59       306\n\n    accuracy                           0.73       826\n   macro avg       0.72      0.69      0.70       826\nweighted avg       0.73      0.73      0.72       826\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import ViTConfig, ViTModel\n\nmodel_Res = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n\n# Remove the last layer of the model Res\nlayers_Res = list(model_Res.children())\nmodel_Res = nn.Sequential(*layers_Res[:-1])\n\n# Set the top layers to be not trainable\ncount = 0\n\n\n# for child in model_Res.children():\n#     count += 1\n#     if count < 8:\n#         for param in child.parameters():\n#             param.requires_grad = False\n \n\nmodel_trans = ViTModel.from_pretrained('google/vit-base-patch16-224')\n# count = 0\n# for child in model_trans.children():\n#     count += 1\n#     if count < 4:\n#         for param in child.parameters():\n#             param.requires_grad = False\n\nlayers_trans = list(model_trans.children()) # Get all the layers from the Transformer model\nmodel_trans_top = nn.Sequential(*layers_trans[:-2]) # Remove the normalization layer and pooler layer\ntrans_layer_norm = list(model_trans.children())[2] # Get the normalization layer","metadata":{"execution":{"iopub.status.busy":"2023-11-18T23:14:54.126906Z","iopub.execute_input":"2023-11-18T23:14:54.127776Z","iopub.status.idle":"2023-11-18T23:15:15.640290Z","shell.execute_reply.started":"2023-11-18T23:14:54.127732Z","shell.execute_reply":"2023-11-18T23:15:15.639380Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nDownloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 221MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1e485b26e7d4424b2d021afc5d929fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9efed8cec03b42878a936d59e33e1866"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at google/vit-base-patch16-224 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass model_final(nn.Module):\n    def __init__(self, model_trans_top, trans_layer_norm, model_Res, dp_rate=0.3):\n        super().__init__()\n\n        # All the trans model layers\n        self.model_trans_top = model_trans_top\n        self.trans_layer_norm = trans_layer_norm\n        self.trans_flatten = nn.Flatten()\n        self.trans_linear = nn.Linear(150528, 2048)\n        self.text_linear = nn.Linear(768, 256)\n\n        # All the ResNet model\n        self.model_Res = model_Res\n\n        # Merge the result and pass through the layers\n        self.dropout = nn.Dropout(dp_rate)\n        self.linear1 = nn.Linear(2304, 500)\n        self.linear2 = nn.Linear(500, 1)\n\n    def forward(self, trans_b, res_b, text_b):\n        # Get intermediate outputs using hidden layer\n        result_trans = self.model_trans_top(trans_b)\n        patch_state = result_trans.last_hidden_state[:, 1:, :]  # Remove the classification token and get the last hidden state of all patches\n        result_trans = self.trans_layer_norm(patch_state)\n        result_trans = self.trans_flatten(patch_state)\n        result_trans = self.dropout(result_trans)\n        result_trans = F.relu(self.trans_linear(result_trans))  # Adding ReLU activation\n\n        result_res = self.model_Res(res_b)\n        result_res = torch.reshape(result_res, (result_res.shape[0], result_res.shape[1]))\n        text_result = F.relu(self.text_linear(text_b))  # Adding ReLU activation\n        text_result = self.dropout(text_result)\n        result_merge = torch.cat((result_trans, text_result), 1)\n        result_merge = self.dropout(result_merge)\n        result_merge = F.relu(self.linear1(result_merge))  # Adding ReLU activation\n        result_merge = self.dropout(result_merge)\n        result_merge = self.linear2(result_merge)\n\n        # Apply sigmoid activation in the final layer for binary classification\n        result_merge = torch.sigmoid(result_merge)\n\n        return result_merge\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T23:15:15.642528Z","iopub.execute_input":"2023-11-18T23:15:15.642909Z","iopub.status.idle":"2023-11-18T23:15:15.654920Z","shell.execute_reply.started":"2023-11-18T23:15:15.642873Z","shell.execute_reply":"2023-11-18T23:15:15.653252Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nmodel = model_final(model_trans_top, trans_layer_norm, model_Res, dp_rate = 0.3)\n\n# Set up optimizer and learing rate scheduel\nparams = [param for param in list(model.parameters()) if param.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.001)\n\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, \n    mode='min', \n    factor=0.1, \n    patience=5, \n    verbose=True)\n\nfrom tqdm import tqdm\n\ndef fit(epochs, model, train_dl, valid_dl):\n    opt = optimizer\n    sched = lr_scheduler\n    loss_func = nn.BCEWithLogitsLoss()\n\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n        model = nn.DataParallel(model)\n        model = model.cuda()\n    else:\n        device = torch.device(\"cpu\")\n\n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        total_loss = 0\n        correct_predictions = 0\n        total_samples = 0\n\n        # Create a new tqdm progress bar for each epoch\n        pbar = tqdm(total=len(train_dl), desc=f'Training Epoch {epoch + 1}/{epochs}')\n\n        for i, (x_trans, x_res, text, yb) in enumerate(train_dl):\n            x_trans = x_trans.to(device, dtype=torch.float32)\n            x_res = x_res.to(device, dtype=torch.float32)\n            text = text.to(device)\n            yb = yb.to(device, dtype=torch.float32)\n\n            preds = model(x_trans, x_res, text)\n            loss = loss_func(preds.squeeze(), yb.squeeze())\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n\n            total_loss += loss.item()\n\n            # Compute accuracy\n            predicted_labels = (preds.squeeze() > 0.5).float()\n            correct_predictions += (predicted_labels == yb).sum().item()\n            total_samples += yb.size(0)\n            # Calculate average loss and accuracy for the current batch\n            train_average_loss = total_loss / (i+1)\n            train_accuracy = correct_predictions / total_samples\n\n            pbar.set_postfix({'Training Loss': f'{train_average_loss:.4f}', 'Training Accuracy': f'{train_accuracy:.4f}'})\n            pbar.update(1)  # Update tqdm progress bar\n\n        pbar.close()  # Close tqdm progress bar for the training epoch\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        val_correct_predictions = 0\n        val_total_samples = 0\n\n        with torch.no_grad():\n            # Create a new tqdm progress bar for validation\n            pbar_val = tqdm(total=len(valid_dl), desc=f'Validation Epoch {epoch + 1}/{epochs}')\n\n            for x_trans_val, x_res_val, text_val, yb_val in valid_dl:\n                x_trans_val = x_trans_val.to(device, dtype=torch.float32)\n                x_res_val = x_res_val.to(device, dtype=torch.float32)\n                text_val = text_val.to(device)\n                yb_val = yb_val.to(device, dtype=torch.float32)\n\n                preds_val = model(x_trans_val, x_res_val, text_val)\n                loss_val = loss_func(preds_val.squeeze(), yb_val.squeeze())\n\n                val_loss += loss_val.item()\n\n                # Compute accuracy for validation\n                predicted_labels_val = (preds_val.squeeze() > 0.5).float()\n                val_correct_predictions += (predicted_labels_val == yb_val).sum().item()\n                val_total_samples += yb_val.size(0)\n\n                pbar_val.update(1)  # Update tqdm progress bar\n\n            pbar_val.close()  # Close tqdm progress bar for validation\n\n        # Calculate average loss and accuracy for both training and validation\n        train_average_loss = total_loss / len(train_dl)\n        train_accuracy = correct_predictions / total_samples\n\n        val_average_loss = val_loss / len(valid_dl)\n        val_accuracy = val_correct_predictions / val_total_samples\n\n        print(f'Training Loss: {train_average_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n        print(f'Validation Loss: {val_average_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n\n        # Learning rate scheduler step based on validation loss\n        sched.step(val_average_loss)\n\n# Example usage:\n# fit(epochs, model, train_dataloader, optimizer, lr_scheduler)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T23:15:15.657597Z","iopub.execute_input":"2023-11-18T23:15:15.657882Z","iopub.status.idle":"2023-11-18T23:15:18.319937Z","shell.execute_reply.started":"2023-11-18T23:15:15.657851Z","shell.execute_reply":"2023-11-18T23:15:18.319148Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport numpy as np\nfrom transformers import BertTokenizer, BertModel\nimport torch\n\n# Load pre-trained BERT model and tokenizer\nmodel_name = 'bert-base-uncased'  # You can change this to the desired BERT variant\ntokenizer = BertTokenizer.from_pretrained(model_name)\nbert = BertModel.from_pretrained(model_name)\ndata = pd.read_csv(\"/kaggle/input/dm-dataset/data mining project/hatefulmemes.csv\")\n# Filter DataFrame based on existing image files\ndata['img_exists'] = data['img'].apply(lambda x: os.path.exists(f\"/kaggle/input/dm-dataset/data mining project/{x}\"))\ndata = data[data['img_exists']]\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Assuming df is your DataFrame\n# Replace 'target_column' with the actual name of your target column\ntarget_column = 'label'\nfeatures_columns = ['img', 'text']\n\n# Split the DataFrame into features and target\nX = data[features_columns]\ny = data[target_column]\n\n# Split the data into training and validation sets\n# Adjust the test_size and random_state as needed\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Optionally, create new DataFrames for training and validation\ntrain_df = pd.concat([X_train, y_train], axis=1)\nvalid_df = pd.concat([X_valid, y_valid], axis=1)\n\n# Display the shapes of the resulting DataFrames\nprint(\"Training Data Shape:\", train_df.shape)\nprint(\"Validation Data Shape:\", valid_df.shape)\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.data = self.data.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data.loc[idx, 'text']\n        img_path = self.data.loc[idx, 'img']\n        label = int(self.data.loc[idx, 'label'])\n\n    \n        img = Image.open(f\"/kaggle/input/dm-dataset/data mining project/{img_path}\").convert('RGB')\n      \n        \n        label = np.array(label)\n        if self.transform:\n            img_tr = self.transform(img)\n        img = img.resize((224,224))\n        img = np.array(img)\n        img = np.transpose(img, (2, 0, 1))\n        \n        tokens = tokenizer(text, return_tensors='pt')\n\n        # Forward pass through BERT model\n        with torch.no_grad():\n            outputs = bert(**tokens)\n\n        # Extract embeddings from the last layer\n        text_embeddings = outputs.last_hidden_state.mean(dim=1)\n#         text_embeddings = text_embeddings.squeeze()\n        \n\n        return img,img_tr,text_embeddings.squeeze(),label\n\n# Example usage:\n# Define the transformations for image preprocessing\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n# Create an instance of the CustomDataset\ntrain_dataset = CustomDataset(data=train_df, transform=image_transform)\ntest_dataset = CustomDataset(data=valid_df, transform=image_transform)\n\n\n\n# Assuming you have a DataLoader\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=1)\n\n# Train the model using the fit function\n# (You need to define your model before using the fit function)\n# fit(epochs, your_model, train_dataloader)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T23:15:18.322285Z","iopub.execute_input":"2023-11-18T23:15:18.322565Z","iopub.status.idle":"2023-11-18T23:15:29.587231Z","shell.execute_reply.started":"2023-11-18T23:15:18.322540Z","shell.execute_reply":"2023-11-18T23:15:29.586162Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fafe7405b0d4bc69d21e46308d21a6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58212cb506ab4aafa73d34fef9a17973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f56b17b6a4a4641bbf16bbc14beccab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3db98573b1e49b3a1449b0deb182b77"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"Training Data Shape: (3422, 3)\nValidation Data Shape: (856, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 10\nfit(epochs, model, train_dataloader, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T23:15:29.588341Z","iopub.execute_input":"2023-11-18T23:15:29.588630Z","iopub.status.idle":"2023-11-19T00:58:48.260363Z","shell.execute_reply.started":"2023-11-18T23:15:29.588604Z","shell.execute_reply":"2023-11-19T00:58:48.259296Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Training Epoch 1/10: 100%|██████████| 107/107 [08:37<00:00,  4.84s/it, Training Loss=0.6953, Training Accuracy=0.6394]\nValidation Epoch 1/10: 100%|██████████| 27/27 [02:07<00:00,  4.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6953, Training Accuracy: 0.6394\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/10: 100%|██████████| 107/107 [08:12<00:00,  4.60s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 2/10: 100%|██████████| 27/27 [02:01<00:00,  4.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3/10: 100%|██████████| 107/107 [08:17<00:00,  4.65s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 3/10: 100%|██████████| 27/27 [02:00<00:00,  4.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4/10: 100%|██████████| 107/107 [08:14<00:00,  4.62s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 4/10: 100%|██████████| 27/27 [02:00<00:00,  4.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5/10: 100%|██████████| 107/107 [08:12<00:00,  4.60s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 5/10: 100%|██████████| 27/27 [02:02<00:00,  4.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6/10: 100%|██████████| 107/107 [08:18<00:00,  4.66s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 6/10: 100%|██████████| 27/27 [02:01<00:00,  4.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7/10: 100%|██████████| 107/107 [08:17<00:00,  4.65s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 7/10: 100%|██████████| 27/27 [02:02<00:00,  4.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\nEpoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8/10: 100%|██████████| 107/107 [08:17<00:00,  4.65s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 8/10: 100%|██████████| 27/27 [02:03<00:00,  4.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9/10: 100%|██████████| 107/107 [08:15<00:00,  4.63s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 9/10: 100%|██████████| 27/27 [02:01<00:00,  4.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10/10: 100%|██████████| 107/107 [08:10<00:00,  4.58s/it, Training Loss=0.6931, Training Accuracy=0.6414]\nValidation Epoch 10/10: 100%|██████████| 27/27 [01:57<00:00,  4.35s/it]","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.6931, Training Accuracy: 0.6414\nValidation Loss: 0.6931, Validation Accuracy: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\npredictions = model.predict([test_image_data, test_text_data])\npredictions_labels = []\nfor i in predictions:\n    if i >= 0.5:\n        predictions_labels.append(1)\n    else:\n        predictions_labels.append(0)\n\n# Compute the AUROC\nauroc = roc_auc_score(test_labels, predictions_labels)\n\nprint(f'AUROC: {auroc}')","metadata":{"execution":{"iopub.status.busy":"2023-11-19T00:59:41.970399Z","iopub.execute_input":"2023-11-19T00:59:41.971223Z","iopub.status.idle":"2023-11-19T00:59:43.134721Z","shell.execute_reply.started":"2023-11-19T00:59:41.971186Z","shell.execute_reply":"2023-11-19T00:59:43.133353Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msklearn\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmetrics\u001b[0m \u001b[94mimport\u001b[0m roc_auc_score                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 2 predictions = model.predict([test_image_data, test_text_data])                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mpredictions_labels = []                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m predictions:                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m i >= \u001b[94m0.5\u001b[0m:                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1614\u001b[0m in \u001b[92m__getattr__\u001b[0m           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1611 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodules = \u001b[96mself\u001b[0m.\u001b[91m__dict__\u001b[0m[\u001b[33m'\u001b[0m\u001b[33m_modules\u001b[0m\u001b[33m'\u001b[0m]                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1612 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m name \u001b[95min\u001b[0m modules:                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1613 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m modules[name]                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1614 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m.format(                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1615 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mtype\u001b[0m(\u001b[96mself\u001b[0m).\u001b[91m__name__\u001b[0m, name))                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1616 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1617 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__setattr__\u001b[0m(\u001b[96mself\u001b[0m, name: \u001b[96mstr\u001b[0m, value: Union[Tensor, \u001b[33m'\u001b[0m\u001b[33mModule\u001b[0m\u001b[33m'\u001b[0m]) -> \u001b[94mNone\u001b[0m:             \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'model_final'\u001b[0m object has no attribute \u001b[32m'predict'\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">sklearn.metrics</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> roc_auc_score                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 2 predictions = model.predict([test_image_data, test_text_data])                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>predictions_labels = []                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> predictions:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> i &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.5</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1614</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1611 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>modules = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__dict__</span>[<span style=\"color: #808000; text-decoration-color: #808000\">'_modules'</span>]                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1612 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> modules:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1613 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> modules[name]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1614 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"'{}' object has no attribute '{}'\"</span>.format(                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1615 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, name))                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1616 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1617 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__setattr__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, value: Union[Tensor, <span style=\"color: #808000; text-decoration-color: #808000\">'Module'</span>]) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_final'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'predict'</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Compute confusion matrix\ncm = confusion_matrix(test_labels, predictions_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_labels, predictions_labels))","metadata":{},"execution_count":null,"outputs":[]}]}